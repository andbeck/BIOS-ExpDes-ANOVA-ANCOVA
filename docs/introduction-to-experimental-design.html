<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 3 Introduction To Experimental Design | An Introduction to Experimental Design ANOVA and ANCOVA</title>
<meta name="author" content="Andrew P Beckerman (with support from text and slides from Mark Rees and Gareth Phoenix)">
<meta name="description" content="Experiments help us answer questions, but there are also non-experimental techniques. What is so special about experiments? One of the central features of an experiment is the treatment - a...">
<meta name="generator" content="bookdown 0.30 with bs4_book()">
<meta property="og:title" content="Chapter 3 Introduction To Experimental Design | An Introduction to Experimental Design ANOVA and ANCOVA">
<meta property="og:type" content="book">
<meta property="og:description" content="Experiments help us answer questions, but there are also non-experimental techniques. What is so special about experiments? One of the central features of an experiment is the treatment - a...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 3 Introduction To Experimental Design | An Introduction to Experimental Design ANOVA and ANCOVA">
<meta name="twitter:description" content="Experiments help us answer questions, but there are also non-experimental techniques. What is so special about experiments? One of the central features of an experiment is the treatment - a...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.0/transition.js"></script><script src="libs/bs3compat-0.4.0/tabs.js"></script><script src="libs/bs3compat-0.4.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">An Introduction to Experimental Design ANOVA and ANCOVA</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="readings--.html"><span class="header-section-number">2</span> Readings —-</a></li>
<li><a class="active" href="introduction-to-experimental-design.html"><span class="header-section-number">3</span> Introduction To Experimental Design</a></li>
<li><a class="" href="some-initial-examples-and-challenge-questions.html"><span class="header-section-number">4</span> Some initial examples and challenge questions</a></li>
<li><a class="" href="design-and-analysis-of-experiments.html"><span class="header-section-number">5</span> Design and Analysis of Experiments</a></li>
<li><a class="" href="designs-for-testing-for-interactions-the-two-way-anova-and-factorial-designs..html"><span class="header-section-number">6</span> Designs for testing for interactions: the two-way ANOVA and factorial designs.</a></li>
<li><a class="" href="interactions-part-2-introducing-the-ancova-analysis-of-covariance.html"><span class="header-section-number">7</span> Interactions Part 2: Introducing the ANCOVA (analysis of covariance)</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="introduction-to-experimental-design" class="section level1" number="3">
<h1>
<span class="header-section-number">3</span> Introduction To Experimental Design<a class="anchor" aria-label="anchor" href="#introduction-to-experimental-design"><i class="fas fa-link"></i></a>
</h1>
<p>Experiments help us answer questions, but there are also non-experimental techniques. What is so special about experiments?</p>
<p>One of the central features of an experiment is the <em>treatment</em> - a manipulation of some variable of interest that should have an effect on the response variable we are investigating. Whether you are manipulating the levels of a hormone to explore it’s impact on a cell/organ or embryo development, the concentration of a drug to explore it’s efficancy in treating a disease or the levels of nitrogen in soil to explore the impacts on plant growth, a treatment is a deliberate manipulation.</p>
<p>It is also important to remember that there can be <em>natural</em> treatments - there may be natural variation among cells, organisms or gradients in the environment that you can use to represent treatments.</p>
<p>So, to be very clear:</p>
<ol style="list-style-type: decimal">
<li>Experiments allow us to set up a direct comparison among the <em>levels</em> or <em>values</em> of <em>treatments</em> of interest.</li>
<li>We can design experiments to minimize any bias in the comparison.</li>
<li>We can design experiments so that the error in the comparison is small.</li>
<li>We design experiments to be in control, and having that control allows us to make stronger inferences about the nature of differences that we see in the response variable.</li>
</ol>
<blockquote>
<p>Experiments allow us to move towards making inferences about causation.</p>
</blockquote>
<p>This last point distinguishes an experiment from an observational study. In an observational study we merely observe which units are in which treatment groups; we don’t get to <em>control that assignment</em>. This underpins the classic issue with assigning <em>causation to correlation</em> - in the following two examples, there is a strong association between the variables, but there has been no control/manipulation.</p>
<p><img src="images/IceCream_Shark.png" width="268"><img src="images/Autism_Organic.png" width="320"></p>
<div id="conepts-associated-with-causation" class="section level2" number="3.1">
<h2>
<span class="header-section-number">3.1</span> Conepts associated with causation<a class="anchor" aria-label="anchor" href="#conepts-associated-with-causation"><i class="fas fa-link"></i></a>
</h2>
<p>Mosteller and Tukey (1977) list three concepts associated with causation and state that at least two (preferably all three) are needed to support a causal relationship:</p>
<ul>
<li>
<em>Consistency</em> – make a change and the response is in the same direction or the amount of response is <em>consistent</em> across populations</li>
<li>
<em>Responsiveness</em> – make a change and the response changes according to theory</li>
<li>
<em>Mechanism</em> – make a change and we can monitor/identify a mechanism leading from cause to effect</li>
</ul>
<p>Let’s look at a classic example. Smoking and lung cancer – from 1922 to 1947 annual deaths for lung cancer went from 612 to 9287 (Observation). This was thought in the 1950s to be either an effect of smoking tobacco or atmospheric pollution (Hypothesis). Numerous studies showed that lung cancer was more prevalent in smokers (Observation: <em>consistency</em>). Chemical analyses of tobacco showed it contained carcinogens (Association: <em>mechanism</em>). Public health programs resulted in a reduction in smoking and lung cancer rates decreased (Intervention: <em>responsiveness</em>).</p>
<p>Note the initial study was an observational study and in this case it was not ethical to do the experiment per se!</p>
</div>
<div id="components-of-an-experiment" class="section level2" number="3.2">
<h2>
<span class="header-section-number">3.2</span> Components of an Experiment<a class="anchor" aria-label="anchor" href="#components-of-an-experiment"><i class="fas fa-link"></i></a>
</h2>
<p>An experiment has <em>treatments, experimental units, responses, and a method to assign treatments to units</em>. These four things specify the experimental design.</p>
<p>Not all experimental designs are created equal. A good experimental design must adhere to the 3Rs. It should reveal consistency, responsiveness and mechanism. The way this happens is by avoiding systematic error in measuring things, and allow estimation of error in measurements with precision.</p>
<div id="the-holy-grail-of-a-control" class="section level3" number="3.2.1">
<h3>
<span class="header-section-number">3.2.1</span> The holy grail of a control<a class="anchor" aria-label="anchor" href="#the-holy-grail-of-a-control"><i class="fas fa-link"></i></a>
</h3>
<p>At this point, it would be very good to revisit the APS 240 sections <a href="https://dzchilds.github.io/stats-for-bio/principles-experimental-design.html#experimental-control">on controls</a> and <a href="https://dzchilds.github.io/stats-for-bio/principles-experimental-design.html#EXPT-DESIGN-PROCEDURAL-CONTROLS">procedural controls</a></p>
</div>
</div>
<div id="so-what-does-a-good-experimental-design-do" class="section level2" number="3.3">
<h2>
<span class="header-section-number">3.3</span> So what does a good experimental design do?<a class="anchor" aria-label="anchor" href="#so-what-does-a-good-experimental-design-do"><i class="fas fa-link"></i></a>
</h2>
<p>In short, a good experimental design must:</p>
<ul>
<li>Avoid systematic error</li>
<li>Allow estimation of error</li>
<li>Be precise</li>
<li>Have broad validity.</li>
</ul>
<p>Lets walk through some definitions.</p>
<p>If our experiment has <em>systematic error</em>, then our comparisons will be biased, no matter how precise our measurements are or how many experimental units we use. <strong>Randomisation</strong> is our tool to combat <em>systematic error</em>.</p>
<p>Even without <em>systematic error</em>, there will be random error in the responses - this is what we call variation in what we are measuring or more formally variance. Such variation in responses invariably leads to random error in the treatment comparisons. When we compared two means in the t-test, we had to deal with the variation in both groups!</p>
<p>Experiments are precise when this random error in the treatment comparisons is small. Precision depends on the size of the random errors in the responses, the number of units used (<strong>replication</strong>), and the experimental design used.</p>
<p>Experiments must be designed so that we have an estimate of the size of random error. This permits statistical inference: for example, confidence intervals (which arise from standard errors) or tests of significance based on t- or F-statistics.</p>
<p>We cannot do inference without an estimate of this variation. We would like our conclusions to be valid for a wide population, so we need to <em>randomise</em> our subjects or objects we are measuring - for example, we may need to be aware of both sexes and of young and old individuals. But there are always compromises - for example, broadening the scope of validity by using a variety of experimental units may decrease the precision of the responses.</p>
</div>
<div id="how-do-we-increase-precision-and-reduce-bias" class="section level2" number="3.4">
<h2>
<span class="header-section-number">3.4</span> How do we increase precision and reduce bias?<a class="anchor" aria-label="anchor" href="#how-do-we-increase-precision-and-reduce-bias"><i class="fas fa-link"></i></a>
</h2>
<p>There are several key concepts</p>
<div id="blinding" class="section level3" number="3.4.1">
<h3>
<span class="header-section-number">3.4.1</span> Blinding<a class="anchor" aria-label="anchor" href="#blinding"><i class="fas fa-link"></i></a>
</h3>
<p><em>Blinding</em> occurs when the evaluators of a response do not know which treatment was given to which unit. Blinding helps prevent bias in the evaluation, even unconscious bias from well-intentioned evaluators. Double blinding occurs when both the evaluators of the response and the (human subject) experimental units do not know the assignment of treatments to units. Blinding the subjects can also prevent bias, because subject responses can change when subjects have expectations for certain treatments.</p>
</div>
<div id="placebos" class="section level3" number="3.4.2">
<h3>
<span class="header-section-number">3.4.2</span> Placebos<a class="anchor" aria-label="anchor" href="#placebos"><i class="fas fa-link"></i></a>
</h3>
<p><em>Placebo</em> is a null treatment that is used when the <em>act</em> of applying a treatment— any treatment — has an effect. Placebos are often used with human subjects, because people often respond to the process of receiving any treatment: for example,
reduction in headache pain when given a sugar pill. Blinding is important when placebos are used with human subjects. Placebos are also useful for nonhuman subjects. The apparatus for spraying a field with a pesticide may compact the soil. Thus we drive the apparatus over the field, without actually spraying, as a placebo treatment.</p>
</div>
<div id="confounders" class="section level3" number="3.4.3">
<h3>
<span class="header-section-number">3.4.3</span> Confounders<a class="anchor" aria-label="anchor" href="#confounders"><i class="fas fa-link"></i></a>
</h3>
<p><em>Confounding</em> occurs when the effect of one factor or treatment cannot be distinguished from that of another factor or treatment. The two factors or treatments are said to be confounded. Except in very special circumstances, confounding should be avoided. Consider the following example. We plant corn variety A in Yorkshire and corn variety B in Lancashire. In this experiment, we cannot distinguish location effects (Yorkshire vs. Lancashire) from variety effects (cornA vs. cornB) — the variety factor and the location factor are confounded.</p>
<p>This is despite the fact that we know that Yorkshire will be better…. (that’s a joke)</p>
</div>
</div>
<div id="experimental-vs.-measurement-units" class="section level2" number="3.5">
<h2>
<span class="header-section-number">3.5</span> Experimental vs. Measurement units<a class="anchor" aria-label="anchor" href="#experimental-vs.-measurement-units"><i class="fas fa-link"></i></a>
</h2>
<p>A common source of difficulty in designing experiments is the distinction between experimental units and measurement units. We need to know the experimental units, as this is the key value used to generate our inference.</p>
<p>Now is a good time to re-look at the short section on <a href="https://dzchilds.github.io/stats-for-bio/principles-experimental-design.html#jargon-busting">Jargon Busting</a> from the APS 240 book.</p>
<div id="experimental-and-measurement-units-an-example" class="section level3" number="3.5.1">
<h3>
<span class="header-section-number">3.5.1</span> Experimental and measurement units: an example<a class="anchor" aria-label="anchor" href="#experimental-and-measurement-units-an-example"><i class="fas fa-link"></i></a>
</h3>
<p>Consider an educational study, with six classrooms of 25 pupils. Each classroom of students is then assigned, at random, to one of two different reading programmes.</p>
<p>At the end of a six-week term, all the students are evaluated via a common reading exam.</p>
<p><em>The challenge question</em></p>
<blockquote>
<p>Are there six experimental units (the classrooms) or 150 (25*6; the students)? We measured the reading ability of the students… but they were in classroom sets of 25….</p>
</blockquote>
</div>
<div id="identifying-the-experimental-unit---an-example-of-pseudo-replication" class="section level3" number="3.5.2">
<h3>
<span class="header-section-number">3.5.2</span> Identifying the experimental unit - an example of <strong>pseudo-replication</strong><a class="anchor" aria-label="anchor" href="#identifying-the-experimental-unit---an-example-of-pseudo-replication"><i class="fas fa-link"></i></a>
</h3>
<p>To identify the experimental units the key question is: To which <em>thing</em> (students or classrooms) did we randomly allocate our treatments?</p>
<p>If we randomly allocated reading programmes to students, then students would be the experimental units. But we didn’t, so the classroom is the experimental unit – it is the classroom to which we randomly allocated treatments.</p>
<p><em>The classroom is the experimental unit</em>.</p>
<p>However, you are right - we don’t <em>measure</em> how a classroom reads; we measure how students read. Thus <em>students are the measurement units</em> for this experiment.</p>
</div>
<div id="psudo-replication" class="section level3" number="3.5.3">
<h3>
<span class="header-section-number">3.5.3</span> Psudo-replication<a class="anchor" aria-label="anchor" href="#psudo-replication"><i class="fas fa-link"></i></a>
</h3>
<p>Confusing these two things can lead to <strong>pseudo-replication</strong>. Treating measurement units as experimental usually leads to overoptimistic analysis — we will reject null hypotheses more often than we should, and our confidence intervals will be too narrow. The usual way around this is to determine a single response for each experimental unit.</p>
<p>There is additional information on <a href="https://dzchilds.github.io/stats-for-bio/principles-experimental-design.html#independence">Independence and Pseudoreplication</a> in the the APS 240 book.</p>
<div id="independence-an-example" class="section level4" number="3.5.3.1">
<h4>
<span class="header-section-number">3.5.3.1</span> Independence: an example<a class="anchor" aria-label="anchor" href="#independence-an-example"><i class="fas fa-link"></i></a>
</h4>
<p>Consider an experiment with two growth chambers each containing 100 plants. One of the chambers received enhanced C02. One night after collecting data you leave the door open on the C02 chamber and the temperature drops and so the plants grow more slowly. When you come to analyze the data you get a highly significant effect of slow growth. However, that C02 results in reduced plant growth not what you expect (CO2 is good for photosynthesis…).</p>
<p>This is an entirely plausible outcome caused by misallocating plants as the experimental unit - it was really the CO2 chamber… to avoid such problems, one needs many chambers.</p>
<p>Consider a second experiment where you have 200 growth chambers and randomly allocate plants to each. If you <em>forget to close one door</em> it really has no effect as just one plant is affected. In fact, to get the same effect as in the first experiment you would have to accidentally leave the doors open on all 100 of the elevated C02 chambers. This is very unlikely indeed!!!</p>
<blockquote>
<p>There are 9 x 1058 ways selecting 100 chambers from 200 chambers so the chance of accidentally picking all the elevated C02 chambers is 1/ 9x1058￼0 (stars in universe 7 x 1022).</p>
</blockquote>
<p>Proper <strong>randomization</strong> and <strong>replication</strong> is very different from <strong>pseudo-replication</strong>.</p>
</div>
</div>
<div id="randomization-with-replication-protects-against-confounding" class="section level3" number="3.5.4">
<h3>
<span class="header-section-number">3.5.4</span> Randomization with Replication protects against Confounding<a class="anchor" aria-label="anchor" href="#randomization-with-replication-protects-against-confounding"><i class="fas fa-link"></i></a>
</h3>
<p>An experiment is properly randomized if the method for assigning treatments to units involves a known, well-understood probabilistic scheme. The probabilistic scheme is called a randomization.</p>
<blockquote>
<p>In general, more experimental units with fewer measurement units per experimental unit works better.</p>
</blockquote>
<p>No matter which features of the population of experimental units are associated with our response, our randomizations should put approximately <em>half the individuals with these features</em> into <em>each treatment group</em>.</p>
<p>Recall our example above of considering sex and age of subjects and imagine a treatment with two levels (hot and cold). Done well, proper randomisation will put approximately half the males, half the females, half the older, half the younger etc into each of the treatment levels.</p>
<p>The beauty of randomization is that it helps prevent <em>confounding</em>, even for factors that we do not know are important.</p>
</div>
<div id="haphazard-is-not-randomized---beware-the-non-randomized-experiment" class="section level3" number="3.5.5">
<h3>
<span class="header-section-number">3.5.5</span> <strong>Haphazard</strong> is NOT randomized - beware the non-randomized experiment<a class="anchor" aria-label="anchor" href="#haphazard-is-not-randomized---beware-the-non-randomized-experiment"><i class="fas fa-link"></i></a>
</h3>
<p>A company is evaluating two different word processing packages for use by its clerical staff. Part of the evaluation is how quickly a test document can be entered correctly using the two programs. We have 20 test secretaries, and each secretary will enter the document twice, using each programme once.</p>
<p>Suppose that all secretaries did the evaluation in the order A first and B second. Does the second programme have an advantage because the secretary will be familiar with the document and thus enter it faster? Or maybe the second programme will be at a disadvantage because the secretary will be tired and thus slower?</p>
<p>Randomization generally costs little in time and trouble, but it can save us from <code>disaster</code>. The experiment above needs secretaries randomly assigned to A first -&gt; B second and B first -&gt; A second (50% in each!).</p>
<p>Anything that might affect your responses should be <em>randomized</em>! For example</p>
<ul>
<li>If the experimental units are not used simultaneously, you can (should) randomize the order in which they are used.</li>
<li>If the experimental units are not used at the same location, you can (should) randomize the locations at which they are used.</li>
<li>If you use more than one measuring instrument for determining response, you can (should) randomize which units are measured on which instruments.</li>
</ul>
</div>
</div>
<div id="mini-quiz" class="section level2" number="3.6">
<h2>
<span class="header-section-number">3.6</span> Mini-Quiz<a class="anchor" aria-label="anchor" href="#mini-quiz"><i class="fas fa-link"></i></a>
</h2>
<blockquote>
<p>A PhD student want to determine the effects of protein on beetle reproduction, so they design an experiment with a control and protein enhanced diet. To assign beetles to each of the treatments they pour a culture onto the table and catch the first 30 beetles that run to the edge of the table, these receive the protein enhanced diet. The next 30 beetles go in the control. <strong>Is this randomized?</strong></p>
</blockquote>
<p>(Hmm …. is there anything about the first 30 beetles that reach the edge of the table that could <em>bias</em> your inference?)</p>
</div>
<div id="replication-how-many" class="section level2" number="3.7">
<h2>
<span class="header-section-number">3.7</span> Replication: How many?<a class="anchor" aria-label="anchor" href="#replication-how-many"><i class="fas fa-link"></i></a>
</h2>
<p>There is a really common question that people ask. How many replicates do I need? Unfortunatly, there are no simple rules… it depends… on….</p>
<ul>
<li>Resources available ($/£/€ and equipment and time)</li>
<li>Variability of experimental units</li>
<li>Treatment structure</li>
<li>Size of effect (response)</li>
<li>Relative importance of different comparisons</li>
</ul>
<p>There is, however, a set of tools that can help with estimating sample sizes. It’s called power analysis and requires that you have some a priori estimate of the expected variation in your response variable.</p>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="readings--.html"><span class="header-section-number">2</span> Readings —-</a></div>
<div class="next"><a href="some-initial-examples-and-challenge-questions.html"><span class="header-section-number">4</span> Some initial examples and challenge questions</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#introduction-to-experimental-design"><span class="header-section-number">3</span> Introduction To Experimental Design</a></li>
<li><a class="nav-link" href="#conepts-associated-with-causation"><span class="header-section-number">3.1</span> Conepts associated with causation</a></li>
<li>
<a class="nav-link" href="#components-of-an-experiment"><span class="header-section-number">3.2</span> Components of an Experiment</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#the-holy-grail-of-a-control"><span class="header-section-number">3.2.1</span> The holy grail of a control</a></li></ul>
</li>
<li><a class="nav-link" href="#so-what-does-a-good-experimental-design-do"><span class="header-section-number">3.3</span> So what does a good experimental design do?</a></li>
<li>
<a class="nav-link" href="#how-do-we-increase-precision-and-reduce-bias"><span class="header-section-number">3.4</span> How do we increase precision and reduce bias?</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#blinding"><span class="header-section-number">3.4.1</span> Blinding</a></li>
<li><a class="nav-link" href="#placebos"><span class="header-section-number">3.4.2</span> Placebos</a></li>
<li><a class="nav-link" href="#confounders"><span class="header-section-number">3.4.3</span> Confounders</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#experimental-vs.-measurement-units"><span class="header-section-number">3.5</span> Experimental vs. Measurement units</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#experimental-and-measurement-units-an-example"><span class="header-section-number">3.5.1</span> Experimental and measurement units: an example</a></li>
<li><a class="nav-link" href="#identifying-the-experimental-unit---an-example-of-pseudo-replication"><span class="header-section-number">3.5.2</span> Identifying the experimental unit - an example of pseudo-replication</a></li>
<li><a class="nav-link" href="#psudo-replication"><span class="header-section-number">3.5.3</span> Psudo-replication</a></li>
<li><a class="nav-link" href="#randomization-with-replication-protects-against-confounding"><span class="header-section-number">3.5.4</span> Randomization with Replication protects against Confounding</a></li>
<li><a class="nav-link" href="#haphazard-is-not-randomized---beware-the-non-randomized-experiment"><span class="header-section-number">3.5.5</span> Haphazard is NOT randomized - beware the non-randomized experiment</a></li>
</ul>
</li>
<li><a class="nav-link" href="#mini-quiz"><span class="header-section-number">3.6</span> Mini-Quiz</a></li>
<li><a class="nav-link" href="#replication-how-many"><span class="header-section-number">3.7</span> Replication: How many?</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>An Introduction to Experimental Design ANOVA and ANCOVA</strong>" was written by Andrew P Beckerman (with support from text and slides from Mark Rees and Gareth Phoenix). It was last built on 2022-12-05.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
