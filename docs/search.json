[{"path":"index.html","id":"introduction","chapter":"1 Introduction","heading":"1 Introduction","text":"Welcome Introduction Experimental Design ANOVA ANCOVAIn mini-module, ’ll learning principles experimental design analysis classic designes, 2x2 ANOVA ANCOVA experiments.module compulsory , forms foundation complex experiments researcher. major step beyond t-test, 1-way ANOVA, simple regression chi-square contingency table analyses ’ve covered thus far.learning outcome mini-module understand basic ideas aboutReplication, Randomisation Reducing NoisePrecision, Bias Systematic ErrorThe Completely Randomised DesignThe Randomised Block DesignThe 2-way ANOVAThe ANCOVA DesignIn order successful final section course, need feel comfortable 1-way ANOVA Regression model. Please review concepts. can also refer Chapter 5 6 Getting Started R (available online Resource via STARPlus) covers great deal mechanics using R types models. Finally, also need feel comfortable dplyr ggplot - ’ll reinforcing old stuff introducing new tricks.","code":""},{"path":"index.html","id":"the-three-rs-the-foundation-of-experimental-design.","chapter":"1 Introduction","heading":"1.1 The Three Rs: The Foundation of Experimental Design.","text":"get started, ’s vital understand basic principles needed ensure experiments can provide robust reliable inference (answers questions). “3 R’s”.Randomisation: random allocation treatments experimental units, avoid confounding treatment effects unknown effects.Replication: repetition treatment within experiment, quantify natural variation experimental units increase accuracy estimated effects.Reduce noise: controlling much possible conditions experiment, e.g. grouping similar experimental units blocks.point, may want revisit, , following section APS 240 book Randomisation","code":""},{"path":"index.html","id":"the-general-linear-model","chapter":"1 Introduction","heading":"1.2 The General Linear Model","text":"section course focused class model called General Linear Model. GLM. GLM generalised linear model. know, right?general linear model , learned past weeks, model fit R lm() function. includes regression, ANOVA, ANCOVA variations .key characteristics remember models. general linear model following form:\\(y = \\beta_{0}+\\beta_{1}*X_{1}+\\beta_{2}*X_{2}+\\epsilon\\)\\(y\\) response variable, \\(\\beta\\)’s estimated parameters, \\(X\\)’s predictor variables \\(\\epsilon\\) comes Gaussian distribution zero mean constant variance.Let’s decompose bit .two types predictor variable:Metric predictor variables measurements quantity may help predict value response. example, response blood pressure patients clinical trial, age, fat mass height potential metric predictor variables. may know continuous explanatory (independent) variablesFactor variables labels serve categorize response measurements groups, may different expected values. Continuing blood pressure example, factor variables might sex drug treatment received (drug , drug B placebo, example). may also know categorical explanatory (independent) variables., hopefully can see general linear model capable representingANOVA – Analysis variance -> Predictors factors.Regression -> Predictor metric variable (continuous variable).Multiple regression -> Predictors metric variables (continuous variables).ANCOVA - Analysis co-variance -> Predictors mixture metric variables (continuous variables) factors.Finally, important understand non-linear relationships data can modelled linear model:, ask!? Well…. consider equation:\\(y = 0.01 + x + x^{2} + \\epsilon\\)Referring generic model structure ,\\(y = \\beta_{0}+\\beta_{1}*X_{1}+\\beta_{2}*X_{2}+\\epsilon\\)hopefully can see \\(\\beta_{0} = 0.01\\), \\(\\beta_{1} = 0\\) \\(\\beta_{2} = 1\\), \\(X_{2} = X^{2}\\)!Linear models perfectly capable used estimate non-linear relationships!code make figure.","code":"\n# because we are using random numbers\nset.seed(123)\n# set x range\nx <- -100:100\n# define y without error\ny_det <- 0.01+x^2\n# add some random variation\ny <- y_det+rnorm(length(x),0,1000)\n\n# create dataframe and plot\ndf <- data.frame(x, y)\nggplot(df, aes(x = x, y = y))+\n  geom_point()"},{"path":"readings--.html","id":"readings--","chapter":"2 Readings —-","heading":"2 Readings —-","text":"several resources help section stats course, onwardsGetting Started R - Introducton Biologists, Second Edition (available electronic online resource via StarPlus). Specifically Chapter 5 6.Experimental Design Life Sciences - Nick Colegrave Graham Ruxton (seen eBay £2.50!)course, venerable coursebook APS 240: https://dzchilds.github.io/stats--bio/index.html","code":""},{"path":"readings--.html","id":"install-some-extra-packages--","chapter":"2 Readings —-","heading":"2.1 Install some extra packages —-","text":"order make module effective, going use additional resources CRAN.Please install packages, already, using install packages tab RStudio:tidyverseggfortifyagricolaecarvisregpatchwork","code":""},{"path":"introduction-to-experimental-design.html","id":"introduction-to-experimental-design","chapter":"3 Introduction To Experimental Design","heading":"3 Introduction To Experimental Design","text":"Experiments help us answer questions, also non-experimental techniques. special experiments?One central features experiment treatment - manipulation variable interest effect response variable investigating. Whether manipulating levels hormone explore ’s impact cell/organ embryo development, concentration drug explore ’s efficancy treating disease levels nitrogen soil explore impacts plant growth, treatment deliberate manipulation.also important remember can natural treatments - may natural variation among cells, organisms gradients environment can use represent treatments., clear:Experiments allow us set direct comparison among levels values treatments interest.can design experiments minimize bias comparison.can design experiments error comparison small.design experiments control, control allows us make stronger inferences nature differences see response variable.Experiments allow us move towards making inferences causation.last point distinguishes experiment observational study. observational study merely observe units treatment groups; don’t get control assignment. underpins classic issue assigning causation correlation - following two examples, strong association variables, control/manipulation.","code":""},{"path":"introduction-to-experimental-design.html","id":"conepts-associated-with-causation","chapter":"3 Introduction To Experimental Design","heading":"3.1 Conepts associated with causation","text":"Mosteller Tukey (1977) list three concepts associated causation state least two (preferably three) needed support causal relationship:Consistency – make change response direction amount response consistent across populationsResponsiveness – make change response changes according theoryMechanism – make change can monitor/identify mechanism leading cause effectLet’s look classic example. Smoking lung cancer – 1922 1947 annual deaths lung cancer went 612 9287 (Observation). thought 1950s either effect smoking tobacco atmospheric pollution (Hypothesis). Numerous studies showed lung cancer prevalent smokers (Observation: consistency). Chemical analyses tobacco showed contained carcinogens (Association: mechanism). Public health programs resulted reduction smoking lung cancer rates decreased (Intervention: responsiveness).Note initial study observational study case ethical experiment per se!","code":""},{"path":"introduction-to-experimental-design.html","id":"components-of-an-experiment","chapter":"3 Introduction To Experimental Design","heading":"3.2 Components of an Experiment","text":"experiment treatments, experimental units, responses, method assign treatments units. four things specify experimental design.experimental designs created equal. good experimental design must adhere 3Rs. reveal consistency, responsiveness mechanism. way happens avoiding systematic error measuring things, allow estimation error measurements precision.","code":""},{"path":"introduction-to-experimental-design.html","id":"the-holy-grail-of-a-control","chapter":"3 Introduction To Experimental Design","heading":"3.2.1 The holy grail of a control","text":"point, good revisit APS 240 sections controls procedural controls","code":""},{"path":"introduction-to-experimental-design.html","id":"so-what-does-a-good-experimental-design-do","chapter":"3 Introduction To Experimental Design","heading":"3.3 So what does a good experimental design do?","text":"short, good experimental design must:Avoid systematic errorAllow estimation errorBe preciseHave broad validity.Lets walk definitions.experiment systematic error, comparisons biased, matter precise measurements many experimental units use. Randomisation tool combat systematic error.Even without systematic error, random error responses - call variation measuring formally variance. variation responses invariably leads random error treatment comparisons. compared two means t-test, deal variation groups!Experiments precise random error treatment comparisons small. Precision depends size random errors responses, number units used (replication), experimental design used.Experiments must designed estimate size random error. permits statistical inference: example, confidence intervals (arise standard errors) tests significance based t- F-statistics.inference without estimate variation. like conclusions valid wide population, need randomise subjects objects measuring - example, may need aware sexes young old individuals. always compromises - example, broadening scope validity using variety experimental units may decrease precision responses.","code":""},{"path":"introduction-to-experimental-design.html","id":"how-do-we-increase-precision-and-reduce-bias","chapter":"3 Introduction To Experimental Design","heading":"3.4 How do we increase precision and reduce bias?","text":"several key concepts","code":""},{"path":"introduction-to-experimental-design.html","id":"blinding","chapter":"3 Introduction To Experimental Design","heading":"3.4.1 Blinding","text":"Blinding occurs evaluators response know treatment given unit. Blinding helps prevent bias evaluation, even unconscious bias well-intentioned evaluators. Double blinding occurs evaluators response (human subject) experimental units know assignment treatments units. Blinding subjects can also prevent bias, subject responses can change subjects expectations certain treatments.","code":""},{"path":"introduction-to-experimental-design.html","id":"placebos","chapter":"3 Introduction To Experimental Design","heading":"3.4.2 Placebos","text":"Placebo null treatment used act applying treatment— treatment — effect. Placebos often used human subjects, people often respond process receiving treatment: example,\nreduction headache pain given sugar pill. Blinding important placebos used human subjects. Placebos also useful nonhuman subjects. apparatus spraying field pesticide may compact soil. Thus drive apparatus field, without actually spraying, placebo treatment.","code":""},{"path":"introduction-to-experimental-design.html","id":"confounders","chapter":"3 Introduction To Experimental Design","heading":"3.4.3 Confounders","text":"Confounding occurs effect one factor treatment distinguished another factor treatment. two factors treatments said confounded. Except special circumstances, confounding avoided. Consider following example. plant corn variety Yorkshire corn variety B Lancashire. experiment, distinguish location effects (Yorkshire vs. Lancashire) variety effects (cornA vs. cornB) — variety factor location factor confounded.despite fact know Yorkshire better…. (’s joke)","code":""},{"path":"introduction-to-experimental-design.html","id":"experimental-vs.-measurement-units","chapter":"3 Introduction To Experimental Design","heading":"3.5 Experimental vs. Measurement units","text":"common source difficulty designing experiments distinction experimental units measurement units. need know experimental units, key value used generate inference.Now good time re-look short section Jargon Busting APS 240 book.","code":""},{"path":"introduction-to-experimental-design.html","id":"experimental-and-measurement-units-an-example","chapter":"3 Introduction To Experimental Design","heading":"3.5.1 Experimental and measurement units: an example","text":"Consider educational study, six classrooms 25 pupils. classroom students assigned, random, one two different reading programmes.end six-week term, students evaluated via common reading exam.challenge questionAre six experimental units (classrooms) 150 (25*6; students)? measured reading ability students… classroom sets 25….","code":""},{"path":"introduction-to-experimental-design.html","id":"identifying-the-experimental-unit---an-example-of-pseudo-replication","chapter":"3 Introduction To Experimental Design","heading":"3.5.2 Identifying the experimental unit - an example of pseudo-replication","text":"identify experimental units key question : thing (students classrooms) randomly allocate treatments?randomly allocated reading programmes students, students experimental units. didn’t, classroom experimental unit – classroom randomly allocated treatments.classroom experimental unit.However, right - don’t measure classroom reads; measure students read. Thus students measurement units experiment.","code":""},{"path":"introduction-to-experimental-design.html","id":"psudo-replication","chapter":"3 Introduction To Experimental Design","heading":"3.5.3 Psudo-replication","text":"Confusing two things can lead pseudo-replication. Treating measurement units experimental usually leads overoptimistic analysis — reject null hypotheses often , confidence intervals narrow. usual way around determine single response experimental unit.additional information Independence Pseudoreplication APS 240 book.","code":""},{"path":"introduction-to-experimental-design.html","id":"independence-an-example","chapter":"3 Introduction To Experimental Design","heading":"3.5.3.1 Independence: an example","text":"Consider experiment two growth chambers containing 100 plants. One chambers received enhanced C02. One night collecting data leave door open C02 chamber temperature drops plants grow slowly. come analyze data get highly significant effect slow growth. However, C02 results reduced plant growth expect (CO2 good photosynthesis…).entirely plausible outcome caused misallocating plants experimental unit - really CO2 chamber… avoid problems, one needs many chambers.Consider second experiment 200 growth chambers randomly allocate plants . forget close one door really effect just one plant affected. fact, get effect first experiment accidentally leave doors open 100 elevated C02 chambers. unlikely indeed!!!9 x 1058 ways selecting 100 chambers 200 chambers chance accidentally picking elevated C02 chambers 1/ 9x1058￼0 (stars universe 7 x 1022).Proper randomization replication different pseudo-replication.","code":""},{"path":"introduction-to-experimental-design.html","id":"randomization-with-replication-protects-against-confounding","chapter":"3 Introduction To Experimental Design","heading":"3.5.4 Randomization with Replication protects against Confounding","text":"experiment properly randomized method assigning treatments units involves known, well-understood probabilistic scheme. probabilistic scheme called randomization.general, experimental units fewer measurement units per experimental unit works better.matter features population experimental units associated response, randomizations put approximately half individuals features treatment group.Recall example considering sex age subjects imagine treatment two levels (hot cold). Done well, proper randomisation put approximately half males, half females, half older, half younger etc treatment levels.beauty randomization helps prevent confounding, even factors know important.","code":""},{"path":"introduction-to-experimental-design.html","id":"haphazard-is-not-randomized---beware-the-non-randomized-experiment","chapter":"3 Introduction To Experimental Design","heading":"3.5.5 Haphazard is NOT randomized - beware the non-randomized experiment","text":"company evaluating two different word processing packages use clerical staff. Part evaluation quickly test document can entered correctly using two programs. 20 test secretaries, secretary enter document twice, using programme .Suppose secretaries evaluation order first B second. second programme advantage secretary familiar document thus enter faster? maybe second programme disadvantage secretary tired thus slower?Randomization generally costs little time trouble, can save us disaster. experiment needs secretaries randomly assigned first -> B second B first -> second (50% !).Anything might affect responses randomized! exampleIf experimental units used simultaneously, can () randomize order used.experimental units used location, can () randomize locations used.use one measuring instrument determining response, can () randomize units measured instruments.","code":""},{"path":"introduction-to-experimental-design.html","id":"mini-quiz","chapter":"3 Introduction To Experimental Design","heading":"3.6 Mini-Quiz","text":"PhD student want determine effects protein beetle reproduction, design experiment control protein enhanced diet. assign beetles treatments pour culture onto table catch first 30 beetles run edge table, receive protein enhanced diet. next 30 beetles go control. randomized?(Hmm …. anything first 30 beetles reach edge table bias inference?)","code":""},{"path":"introduction-to-experimental-design.html","id":"replication-how-many","chapter":"3 Introduction To Experimental Design","heading":"3.7 Replication: How many?","text":"really common question people ask. many replicates need? Unfortunatly, simple rules… depends… ….Resources available ($/£/€ equipment time)Variability experimental unitsTreatment structureSize effect (response)Relative importance different comparisonsThere , however, set tools can help estimating sample sizes. ’s called power analysis requires priori estimate expected variation response variable.","code":""},{"path":"some-initial-examples-and-challenge-questions.html","id":"some-initial-examples-and-challenge-questions","chapter":"4 Some initial examples and challenge questions","heading":"4 Some initial examples and challenge questions","text":"section, review field based experimental design example. challenge questions answer.also introduce tools generate randomised experimental designs - good trick sleeves!","code":""},{"path":"some-initial-examples-and-challenge-questions.html","id":"designing-your-first-experiment","chapter":"4 Some initial examples and challenge questions","heading":"4.1 Designing your first experiment","text":"challenged design Arctic field manipulation experiment evaluate UV-B radiation increased \\(CO_{2}\\) impacts plant growth.Context: arctic tundra studyIncreasing ultraviolet-B (+UV-B) radiation ozone depletion (arctic ozone hole)Increasing atmospheric \\(CO_{2}\\) (\\(+CO_{2}\\)) anthropogenic emissionsFor plants: +UV-B potentially harmful, +CO2 potentially beneficialHypothesesElevated (+) UV-B radiation reduce growth arctic plantsElevated (+) \\(CO_{2}\\) increase growth arctic plantsThe resources available constrained. arctic research station given permission 16 plots (2m x 2m) natural vegetation nearby.One +UV-B plot (2m x 2m) costs £4000 (provides UV-B lamps, frame, power control system, wooden walkways around plots)One \\(+CO_{2}\\) plot (2m x 2m) costs £6000 (provides \\(CO_{2}\\) release system, \\(CO_{2}\\) control covers \\(CO_{2}\\) purchase costs, wooden walkways around plots)One control plot (2m x 2m) costs £200 (marking posts, wooden walkways around plots)budget £61,000Design experiment test hypotheses (.e. design plots treatments including replication, measurements take - plant growth rates….). Think hard . many treatments ? many plots/treatment like allocate? possible? balanced design, given max budget? isn’t, rule can use allocate replicates treatments?Write answer , moving next section (part package challenges). ’ll provide answer separately!","code":""},{"path":"design-and-analysis-of-experiments.html","id":"design-and-analysis-of-experiments","chapter":"5 Design and Analysis of Experiments","heading":"5 Design and Analysis of Experiments","text":"section going learn implement two experimental designs:CRD: completely randomised designCRBD: completely randomised block design.two designs valuable dealing two things make hard make strong inference experiments: noise counfounding effects.unwated sources variation comes two forms (see APS 240 reading)first confounding variation. occurs one sources variation work parallel factor investigating make hard, impossible, unambiguously attribute effects see single cause. Confounding variation particularly problematic observational studies , definition, don’t manipulate factors ’re interested .first confounding variation. occurs one sources variation work parallel factor investigating make hard, impossible, unambiguously attribute effects see single cause. Confounding variation particularly problematic observational studies , definition, don’t manipulate factors ’re interested .second noise. describes variation unrelated factor investigating adds variability results harder see, detect statistically, effect factor. noted , much experimental design improving ability account noise statistical analysis.second noise. describes variation unrelated factor investigating adds variability results harder see, detect statistically, effect factor. noted , much experimental design improving ability account noise statistical analysis.consider together, techniques dealing applicable . primary tools dealing arerandomisationblockingappropriate controlsadditional treatments.following sections, going focus first three. , also revisit make inference 1-way ANOVA experiments introduce generalised approach making contrasts want. recall 1-way ANOVA work previous module (Week 7), learned treatment contrasts, default comparison means reference level, Tukey test, makes pairwise comparisons. find intermediate zone.","code":""},{"path":"design-and-analysis-of-experiments.html","id":"a-crd-completely-randomised-design-example","chapter":"5 Design and Analysis of Experiments","heading":"5.1 A CRD (Completely Randomised Design) Example","text":"experiment plant crop biomass yield several herbicide treatments - herbicide targets weeds target plant (e.g. Glyphosate): control two herbicides, third treatment placebo - applied water herbicide.data example called plantYield.csv.treatment, n = 30 plants separate pots standarised conditions.Can explain using placebo? know measurement experimental unit? 1-way ANOVA, baseline hypothesis? Given control two herbicides, alternative hypotheses might test?Let’s look structure design. hoped, 30 replicates treatment. second view reveals replicates allocated randomly among replicate plants. order values treat column.now added data design order start statistics. TRUTH data average, controls yield 20, Herbicide 1 increases yield 5, Herbicide 2 6 placebo 1 unit. data also quite variable. standard deviation around yields large. going analyse data andsee can recover estimates ‘known’ yield.test null hypothesis.test hypothesis herbicides, average, increase yield.test whether two herbicides different.test whether placebo different control.answer one questions !","code":"## treat\n##    Cont   Herb1   Herb2 Placebo \n##      30      30      30      30##    plots r   treat\n## 1      1 1 Placebo\n## 2      2 2 Placebo\n## 3      3 1    Cont\n## 4      4 3 Placebo\n## 5      5 1   Herb2\n## 6      6 2    Cont\n## 7      7 1   Herb1\n## 8      8 2   Herb2\n## 9      9 3    Cont\n## 10    10 4 Placebo\n# look at the design now.\nhead(plantYield)##   plots r   treat      obs\n## 1     1 1 Placebo 27.54449\n## 2     2 2 Placebo 22.39018\n## 3     3 1    Cont 18.23051\n## 4     4 3 Placebo 19.79473\n## 5     5 1   Herb2 23.46557\n## 6     6 2    Cont 21.65736"},{"path":"design-and-analysis-of-experiments.html","id":"the-dplyr-and-ggplot-pipeline-for-inference.","chapter":"5 Design and Analysis of Experiments","heading":"5.1.1 The dplyr and ggplot pipeline for inference.","text":"Now can move standard data management visualisation pipeline.review data (plantYield.csv file contains data)sumamrise data dplyr - generate means se’s treatmentsvisualise ggplot2A things notice.data quite variable means herbicide treatments roughly 5 6 units higher control. GOOD. expected….standard errors quite small, even though variation large! !?two herbicides don’t look different, especially given variation around treatment. Neither placebo control. need stats.interested extra reading thinking, 95% Confidence Interval around means can calculated using \\(1.96*SE` == `1.96*sd(obs)/sqrt(n())\\). Go ahead look want…","code":"\n# check the data\n# note\n# obs == yield\n# treat == treatment\n# r = replicate (there are 30 of each treatment)\n\nglimpse(plantYield)## Rows: 120\n## Columns: 4\n## $ plots <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 1…\n## $ r     <int> 1, 2, 1, 3, 1, 2, 1, 2, 3, 4, 5, 4, 6, 5, 3, 2, 6, 7, 8, 4, 5, 3…\n## $ treat <chr> \"Placebo\", \"Placebo\", \"Cont\", \"Placebo\", \"Herb2\", \"Cont\", \"Herb1…\n## $ obs   <dbl> 27.54449, 22.39018, 18.23051, 19.79473, 23.46557, 21.65736, 26.5…\n# let's force treat to be a factor.  This will make life easier later...\nplantYield <- plantYield %>% \n  mutate(treat = factor(treat))\n\n# summarise to get means and ses\nsumDat <- plantYield %>% \n  group_by(treat) %>% \n  summarise(\n    # calculate the means\n    meanYield = mean(obs),\n    # calculate the se\n    seYield = sd(obs)/sqrt(n())\n  )\n\n# plot the raw data and the mean±se\n# start with the mean±se and then add the raw data\nggplot(sumDat, aes(x = treat, y = meanYield))+\n  geom_point(size = 5)+\n  geom_errorbar(data = sumDat, aes(ymin = meanYield - seYield, ymax = meanYield+seYield),\n                width = 0.1)+\n  geom_point(data = design, aes(x = treat, y = obs), colour = 'red', alpha = 0.3)"},{"path":"design-and-analysis-of-experiments.html","id":"the-one-way-anova.","chapter":"5 Design and Analysis of Experiments","heading":"5.1.2 The One-Way ANOVA.","text":"’ve paying attention, ’ve essentially designed plotted data 1-way ANOVA. data similar daphnia parasite data finished semester 1 .analyse data, use lm() function build model, check assumptions, make inference. Let’s go.","code":"\n# the model\nmodYield <- lm(obs ~ treat, data = plantYield)\n\n# assumptions\nautoplot(modYield)\n# inference: anova\nanova(modYield)## Analysis of Variance Table\n## \n## Response: obs\n##            Df Sum Sq Mean Sq F value    Pr(>F)    \n## treat       3 807.49 269.164  33.257 1.383e-15 ***\n## Residuals 116 938.85   8.094                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n# contrasts\nsummary(modYield)## \n## Call:\n## lm(formula = obs ~ treat, data = plantYield)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -4.6952 -2.1542 -0.3872  1.8383  7.0609 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)   20.0004     0.5194  38.506  < 2e-16 ***\n## treatHerb1     4.1655     0.7346   5.671 1.06e-07 ***\n## treatHerb2     6.2449     0.7346   8.502 7.43e-14 ***\n## treatPlacebo   0.4832     0.7346   0.658    0.512    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 2.845 on 116 degrees of freedom\n## Multiple R-squared:  0.4624, Adjusted R-squared:  0.4485 \n## F-statistic: 33.26 on 3 and 116 DF,  p-value: 1.383e-15"},{"path":"design-and-analysis-of-experiments.html","id":"making-insight-and-inference","chapter":"5 Design and Analysis of Experiments","heading":"5.1.3 Making insight and inference","text":"Lets walks things discretely.graph suggests herbicide treatments effect increasing yield.model designed test hypothesis - differences among means non-zero?hypothesis probably really whether herbicide placebos different controls. Hail treatment contrast!diagnostics fantastic… best ’ve ever seen.Anova Table confirms differences - can reject null hypothesisThe summary table confirms Herb1 Herb2 larger controls Placebo .interpret even ?estimate associated Control 20! Just .estimates associated Herb1, Herb2 Placebo differences mean treatments control (reference level!). differences positive Herb1 Herb2, close 5 6 respectively (expected) positive difference 0 via statistical test.However, difference Placebo close 0 therefore can reject null hypothesis test differs control. GENUIS!","code":""},{"path":"design-and-analysis-of-experiments.html","id":"a-priori-vs.-post-hoc-contrasts","chapter":"5 Design and Analysis of Experiments","heading":"5.2 A priori vs. Post-Hoc Contrasts","text":"discussed , likely several questions might wanted answer designing experiment. example, two herbicides different effects?","code":""},{"path":"design-and-analysis-of-experiments.html","id":"custom-contrasts-versus-the-tukey-test","chapter":"5 Design and Analysis of Experiments","heading":"5.2.1 Custom contrasts versus the Tukey Test","text":"semester 1, introduced Tukey Test. known posteriori test – testing significance things suggested experiment, also known data snooping data dredging. multiple comparison methods (Bonferroni, Scheffe method, Tukey honest significant difference, Duncan’s multiple range test) try control chance getting significant result chance.understand risks , consider experimental design. 7 treatments. 7 treatments, 21 pairwise comparisons. p-value threshold \\(0.05\\) expect 1/20 (5/100) tests significant. 7 treatment 21 comparison design, expect signficant result chance? betyja., unless priori (advance) can justify pairwise comparisons, Tukey Test may appropriate.statisticians really don’t like :“view multiple comparison methods place interpretation data” -Nelder (well respected statistician).","code":""},{"path":"design-and-analysis-of-experiments.html","id":"the-more-appropriate-approach---custom-contrasts","chapter":"5 Design and Analysis of Experiments","heading":"5.2.1.1 The more appropriate approach - custom contrasts","text":"appropriate approach specify priori (experiment) set hypotheses want test, test using contrasts.experiment, noted , probably interested treatment contrasts provided - tests difference control. others .Specifying specific contrasts easy get head around ‘structure’ syntax.Lets go specifying comparison JUST Herbicide 1 control. Remember model called modYield data called design., says difference control Herbicide 1 ~5 different 0. number 4.16 look familiar? . number summary() table full model. just specified one three treatment contrasts summary() uses.","code":"\n# check the levels and ORDERING of the treatments\n# this function, levels(), tells you this\n# note the ORDER: it is alphabetical, and control comes first\n# the words fill in four slots c(X,X,X,X). \n# we will use these slots....\nlevels(plantYield$treat)## [1] \"Cont\"    \"Herb1\"   \"Herb2\"   \"Placebo\"\n# define the contrast you want using -1, 1 and 0's\n# this says compare control with herbicide 1.... and ignore the Herb2 and Placebo\n# we give the reference -1 to the control slot\n# and the reference 1 to the Herbicide 1 slot.\ncontrast <- c(-1,1,0,0)\n\n# use the fit.contrast function from gmodels\nfit.contrast(modYield, \"treat\", contrast)##                      Estimate Std. Error t value     Pr(>|t|)\n## treat c=( -1 1 0 0 ) 4.165507   0.734555 5.67079 1.058335e-07\n## attr(,\"class\")\n## [1] \"fit_contrast\"\n# remind ourselves of the contrast from the summary table\nsummary(modYield)## \n## Call:\n## lm(formula = obs ~ treat, data = plantYield)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -4.6952 -2.1542 -0.3872  1.8383  7.0609 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)   20.0004     0.5194  38.506  < 2e-16 ***\n## treatHerb1     4.1655     0.7346   5.671 1.06e-07 ***\n## treatHerb2     6.2449     0.7346   8.502 7.43e-14 ***\n## treatPlacebo   0.4832     0.7346   0.658    0.512    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 2.845 on 116 degrees of freedom\n## Multiple R-squared:  0.4624, Adjusted R-squared:  0.4485 \n## F-statistic: 33.26 on 3 and 116 DF,  p-value: 1.383e-15"},{"path":"design-and-analysis-of-experiments.html","id":"a-different-contrast---herbicide-1-vs-herbicide-2.","chapter":"5 Design and Analysis of Experiments","heading":"5.2.1.2 A different contrast - Herbicide 1 vs Herbicide 2.","text":"want compare two herbicides can use approach. Note advance contrast exist summary table!Isn’t cool? quite surprising, right? expect . says despite difference created ~1 unit yield Herb1 Herb2, even big variation, statistics detect significant difference.Note difference reported difference two means calcuated sumDat calculation !:: \\(26.2 - 24.2 = 2\\)","code":"\n# define the contrast you want using -1, 1 and 0's\n# this says compare herb1 with herb2, ignoring the control and placebo.\n# we give the slot for herbicide 1 a \"-1\" and the slot for herbicide 2 a \"1\".\ncontrast <- c(0,-1,1,0)\n\n# use the fit.contrast function from gmodels\nfit.contrast(modYield, \"treat\", contrast)##                      Estimate Std. Error  t value    Pr(>|t|)\n## treat c=( 0 -1 1 0 ) 2.079439   0.734555 2.830882 0.005473189\n## attr(,\"class\")\n## [1] \"fit_contrast\"\n# check our summary data\nsumDat## # A tibble: 4 × 3\n##   treat   meanYield seYield\n##   <fct>       <dbl>   <dbl>\n## 1 Cont         20.0   0.552\n## 2 Herb1        24.2   0.591\n## 3 Herb2        26.2   0.359\n## 4 Placebo      20.5   0.544"},{"path":"design-and-analysis-of-experiments.html","id":"a-more-complex-contrast-comparing-the-average-of-the-herbicide-effect-with-the-control.","chapter":"5 Design and Analysis of Experiments","heading":"5.2.1.3 A more complex contrast: comparing the average of the herbicide effect with the control.","text":"might comparison intended make also… average effect herbicides general. , expand idea -1,1 0’s include 1/2s (yes, 1/3’s possible):cool. custom contrast delivers inference herbicides average increase yield five units., checking sumDat, can see result comes .\\((24.2+26.2)/2 = 25.2\\) –> \\(25.2 - 20 = 5.2\\)","code":"\n# define the contrast you want using -1, 1 and 0's\n# this says compare control with the average of herbicide 1 and 2, ignoring the placebo\n# we give the control slot a -1 and the two herbicide slots a 1/2 each.\ncontrast <- c(-1, 1/2, 1/2, 0)\n\n# use the fit.contrast function from gmodels\nfit.contrast(modYield, \"treat\", contrast)##                          Estimate Std. Error  t value     Pr(>|t|)\n## treat c=( -1 0.5 0.5 0 ) 5.205226  0.6361433 8.182475 4.015904e-13\n## attr(,\"class\")\n## [1] \"fit_contrast\"\nsumDat## # A tibble: 4 × 3\n##   treat   meanYield seYield\n##   <fct>       <dbl>   <dbl>\n## 1 Cont         20.0   0.552\n## 2 Herb1        24.2   0.591\n## 3 Herb2        26.2   0.359\n## 4 Placebo      20.5   0.544"},{"path":"design-and-analysis-of-experiments.html","id":"the-write-up-using-contrasts.","chapter":"5 Design and Analysis of Experiments","heading":"5.2.2 The Write Up using contrasts.","text":"Fill blanks using various contrasts made !conclude herbicides average cause _____ gram increase yield (t = ___ , p = ___ ). also note significant difference _____ grams herbicides (t = _____ p = ______). additional placebo treatment effect yield (t = _______ p = __________).","code":""},{"path":"design-and-analysis-of-experiments.html","id":"coming-back-to-randomisation","chapter":"5 Design and Analysis of Experiments","heading":"5.2.3 Coming Back to Randomisation","text":"worked CRD measurement units completely randomised experimental treatments. simple effort super valuable. ’ve read.Randomisation guards variety possible biases confounding effects, including inadvertent biases might introduced simply process setting experiment…. Randomisation critical method guarding confounding effects. best insurance unwittingly getting factor working parallel treatment.know gradient, feature environment lab system KNOW confound design. way can remove known pattern? Yes…. course .","code":""},{"path":"design-and-analysis-of-experiments.html","id":"the-rcbd---the-randomised-complete-block-design","chapter":"5 Design and Analysis of Experiments","heading":"5.3 THE RCBD - The Randomised Complete Block Design","text":"Blocking allows us reduce known experimental error.block group experimental units homogeneous sense – place, measured time, person. may experience similar temperature, hormone concentration. may simply position incubator light varies front back.constructing blocks try select experimental units homogeneous within blocks blocks, thus units within , may dissimilar.block? use completely randomised design, location timing treatment ‘plots’ (patches different N soil-moisture, incubators, locations 96 well plate) can generate heterogeneity experimental error (variation).consequences ability detect effects. variance Experimental Error increases, confidence intervals get wider power analysis decreases - ’s harder detect effects treatments background noise. Ideally like use experimental units homogeneous experimental error small. Blocking .simplest blocked design Randomized Complete Block design (RCB)one complete set treatments block. sake example, lets imagine identify three ‘blocks’ - soil moisture zones. design , allocate 10/30 replicates treatment block.first block, randomly assign 10 treatments n locations block. independent randomization block. RCB design.example, consider following matrix: rows blocks, letters different treatments. block, treatment represented, different location block (randomisation g treatments n units). blocks sequence - left right - different days, different locations different positions hillside, example representing elevation soil moisture gradient.Blocks designed ‘capture’ underlying source variability allow us detect among treatment differences effectively.example, consider following matrix: rows blocks, letters different treatments. block, treatment represented, different location block (randomisation g treatments n units). blocks sequence - left right - different days, different locations different positions hillside, example representing elevation soil moisture gradient.Blocks designed ‘capture’ underlying source variability allow us detect among treatment differences effectively.another picture block design moves just letters something literal.blocks arranged along gradient, say along side hill, represent low high elevation associated soil moisture. blocks capture background variation. , treatment level (1-4) allocated random position block.  end, treatment level replicated across blocks (n = 6!). : https://www.researchgate.net/publication/322369242_Randomized_Block_Design_probiotic_example/figures?lo=1It important note blocks exist time randomization treatments units. impose blocking structure completely randomized design fact; either randomization blocked .use RCB increase power precision experiment decreasing error variance. decrease error variance achieved finding groups units homogeneous (blocks) , effect, repeating experiment independently different blocks. RCB effective design single source extraneous variation responses can identify ahead time use partition units blocks.short ALWAYS block experiment, can.can spatial blocks, temporal blocks repeat experiment different times, block batch.general, source variation think may influence response can identified prior experiment candidate blocking.","code":"##      [,1] [,2] [,3] [,4] [,5]\n## [1,] \"A\"  \"B\"  \"A\"  \"E\"  \"D\" \n## [2,] \"C\"  \"A\"  \"D\"  \"C\"  \"A\" \n## [3,] \"D\"  \"E\"  \"B\"  \"D\"  \"C\" \n## [4,] \"E\"  \"C\"  \"E\"  \"B\"  \"E\" \n## [5,] \"B\"  \"D\"  \"C\"  \"A\"  \"B\""},{"path":"design-and-analysis-of-experiments.html","id":"an-example-of-the-rcbd","chapter":"5 Design and Analysis of Experiments","heading":"5.4 An example of the RCBD","text":"Lets modify previous example including blocking. wish replicate analysis, data plantYield_Blocked.csv. data, means similar plantYield , Herbicide 1 10 units higher control Herbicide 2 9 units higher. Furthermore, block 1 supposed ~10 units higher blocks 2,3,4 block 5 ~10 units lower.","code":"##    plots block   treat      obs\n## 1     11     1 Placebo 31.18707\n## 2     12     1 Control 31.99603\n## 3     13     1   Herb2 41.29937\n## 4     14     1   Herb1 41.12746\n## 5     21     2 Control 21.08111\n## 6     22     2   Herb1 30.56917\n## 7     23     2   Herb2 28.09290\n## 8     24     2 Placebo 21.02990\n## 9     31     3   Herb2 27.44097\n## 10    32     3   Herb1 30.29749"},{"path":"design-and-analysis-of-experiments.html","id":"analysing-the-crbd","chapter":"5 Design and Analysis of Experiments","heading":"5.5 Analysing the CRBD","text":"’ll leave now generate following plot means ± standard errors plantYield_Blocked.csv file.requires thinking hard use dplyr tools (group_by() summarise()) ggplot (adding one layer two different sources data - summary data raw data). need make sumDat object means se’s. need plot raw data, overlay mean±se info sumDat.Can see variation block 1 5? Block 2-4 similar…. Block 1 10 units , Block 5 10 units less.","code":""},{"path":"design-and-analysis-of-experiments.html","id":"building-the-model","chapter":"5 Design and Analysis of Experiments","heading":"5.5.1 Building the model","text":"order understand ’s going blocking, ’s importance, lets build two models. good trick good process learn. first model naive model ignores block - treating CRB. second model correct model, letting block absorb variation can see among blocks 1, 2-4 5.first important thing focus difference Mean Sq Residual Errors - naive_model, \\(55.52\\). block_model, \\(0.94\\). Wow…. massive reduction residual error…. gone?second important thing notice allocated variation block block_model, thus reducing error variation, treatment effect shifts insignificant significant. point try recall F-tests generated (equation!) really understand blocking made different.","code":"\n# models\nnaive_model <- lm(obs ~ treat, plantYield_Block)\n# note the order of these factors is important\n# put block first.... so we can absorb this variation first\n# the anova() table is a SEQUENTIAL table!\nblock_model <- lm(obs ~ block + treat, plantYield_Block) \n\n# anova tables\nanova(naive_model)## Analysis of Variance Table\n## \n## Response: obs\n##           Df Sum Sq Mean Sq F value  Pr(>F)  \n## treat      3 417.82 139.274  2.5085 0.09579 .\n## Residuals 16 888.34  55.521                  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nanova(block_model)## Analysis of Variance Table\n## \n## Response: obs\n##           Df Sum Sq Mean Sq F value    Pr(>F)    \n## block      4 877.08 219.270  233.68 2.871e-11 ***\n## treat      3 417.82 139.274  148.43 9.469e-10 ***\n## Residuals 12  11.26   0.938                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"design-and-analysis-of-experiments.html","id":"are-the-estimates-of-the-parameters-what-we-expect","chapter":"5 Design and Analysis of Experiments","heading":"5.5.2 Are the estimates of the parameters what we expect?","text":"Lets check model estimating differences might expected. can using summary table.Let’s remember , example, mean Herb1 expected 10 units higher control yield 20, block 1 supposed ~10 units higher 2,3,4.table, INTERCEPT specifying FIRST BLOCK CONTROL TREATMENT LEVEL. know ’s words missing rest table, first alpha-numerially list blocks treatments. Make sure understand . ’s tricky, get , becomes obvious…. look missing rest table!value control, block 1 approximately 30! 20+10, expected.value Herb1 ~10 units higher (remember, value 9.84 DIFFERENCE control treatment).value block 5 reported 20 unites lower block 1 control. correct , , block 1 control 10 units higher control mean (20+10) block 5 10 units lower….Make sure get logic!take home message numbers model make complete sense respect actual data. Furthermore, controlling among block variation gave us power detect treatment effect, something missed estimated block source variation.","code":"\nsummary(block_model)## \n## Call:\n## lm(formula = obs ~ block + treat, data = plantYield_Block)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -1.3505 -0.7196  0.2147  0.6396  1.0719 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)   31.2184     0.6126  50.957 2.14e-15 ***\n## block2       -11.2092     0.6850 -16.365 1.43e-09 ***\n## block3       -12.1132     0.6850 -17.685 5.84e-10 ***\n## block4       -11.3415     0.6850 -16.558 1.25e-09 ***\n## block5       -20.8449     0.6850 -30.433 9.94e-13 ***\n## treatHerb1    10.3450     0.6126  16.886 9.96e-10 ***\n## treatHerb2     9.0721     0.6126  14.808 4.50e-09 ***\n## treatPlacebo   1.3192     0.6126   2.153   0.0523 .  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.9687 on 12 degrees of freedom\n## Multiple R-squared:  0.9914, Adjusted R-squared:  0.9864 \n## F-statistic: 197.1 on 7 and 12 DF,  p-value: 2.009e-11"},{"path":"design-and-analysis-of-experiments.html","id":"correct-standard-errors-for-a-figure","chapter":"5 Design and Analysis of Experiments","heading":"5.5.3 Correct Standard Errors for a Figure","text":"made initial plot , calculated standard error based observations among blocks. However, variation really wish represent variation controlled blocking effects. means standard deviation probably use error variance correct model: \\(0.94\\). Can see comes ? Mean Sq column Residuals row anova() table.standard deviation \\(\\sqrt{Var}\\) thus, correct standard errors model \\(\\sqrt{0.94}\\)","code":""},{"path":"design-and-analysis-of-experiments.html","id":"visreg---a-helpful-package-for-automating-this.","chapter":"5 Design and Analysis of Experiments","heading":"5.5.3.1 visreg - a helpful package for automating this.","text":"nice plotting function package visreg delivers proper standard errors nice ggplot framework.presents points partial residuals (deviation mean replicate), lines depicting means, shaded area 95% confidence interval, calculated \\(1.96*SE\\), SE estimated model error variance (just ). Compare first graph.","code":"\nvisreg(block_model, \"treat\", gg=TRUE)+\n  ylab(\"Yield\") + \n  xlab(\"Treatment\") "},{"path":"design-and-analysis-of-experiments.html","id":"making-inference-in-a-blocked-model-confidence-intervals-and-contrasts","chapter":"5 Design and Analysis of Experiments","heading":"5.5.4 Making inference in a blocked model: confidence intervals and contrasts","text":"now strong position make inference.Let’s start rule thumb linked 95% confidence interval (CI). CIs figure don’t overlap, different; , . indicates Cont Placebo significantly different (95% confidence intervals overlap). Herb1 Herb 2 significantly different , .OK. robust. Instead, let’s revisit post-hoc priori methods evaluating differences among treatments. can apply tukey test calculate pairwise differences. good idea, let’s , using agricolae HSD.test() function. Living large!confirms intuition 95% Confidence Interval insights. correct?Let’s make formal test, using contrast() fit.contrast() functions one pairwise tests looks obvious - Herb1 Herb2. Even block model, second argument fit.contrast() treatment contrast made.Amazing. contrast defining specific test provides different answer post-hoc Tukey test. important… Tukey Test makes lots tests penalised many tests. , contrast correct reliable result. fit.contrast HSD.test manage model complexity variance estimates properly, contrast reduces probability finding significant difference chance failing find one.","code":"\n# use agricolae HSD.test()\n\ntukey_out <- HSD.test(block_model, \"treat\", group = TRUE)\ntukey_out$groups##              obs groups\n## Herb1   30.46167      a\n## Herb2   29.18874      a\n## Placebo 21.43581      b\n## Control 20.11665      b\n# fit.contrast from gmodels package\n# see that even with the block in the model\ncontrast <- c(0,-1,1,0)\nfit.contrast(block_model, \"treat\", contrast)##                       Estimate Std. Error   t value   Pr(>|t|)\n## treat c=( 0 -1 1 0 ) -1.272934  0.6126423 -2.077777 0.05985811\n## attr(,\"class\")\n## [1] \"fit_contrast\""},{"path":"designs-for-testing-for-interactions-the-two-way-anova-and-factorial-designs..html","id":"designs-for-testing-for-interactions-the-two-way-anova-and-factorial-designs.","chapter":"6 Designs for testing for interactions: the two-way ANOVA and factorial designs.","heading":"6 Designs for testing for interactions: the two-way ANOVA and factorial designs.","text":"","code":""},{"path":"designs-for-testing-for-interactions-the-two-way-anova-and-factorial-designs..html","id":"introducing-interactions","chapter":"6 Designs for testing for interactions: the two-way ANOVA and factorial designs.","heading":"6.1 Introducing Interactions","text":"previous sections, 1-way ANOVA module week 7, focused single explanatory variable. week 7, parasite factor. previous chapters focusing yield, herbicide treatment. cases, question asking single, main effect. However, many cases design experiments might two variables. example, may interesting effect parasite growth also whether effect varies amount food available. might interested yeild crop function herbicide, also soil water content. might interested rate cell division function growth hormon, also whether varies presence calcium blocker. cases asking question whether effect one treatment varies level another. Thus, question interaction.jumping example, let’s introduce simple statement forms core asking interpreting interactions.interaction two explanatory variables, X Z, response variable Y, :effect X Y varies Z. effect X Y depends Z.use varies depends defines context dependency ’s defines interactions.","code":""},{"path":"designs-for-testing-for-interactions-the-two-way-anova-and-factorial-designs..html","id":"an-example-with-co2-and-uv-b-solar-radiation-impact-on-plant-growth-in-the-artic.","chapter":"6 Designs for testing for interactions: the two-way ANOVA and factorial designs.","heading":"6.1.1 An Example with CO2 and UV-B solar radiation impact on plant growth in the artic.","text":"Context: arctic tundra study\nIncreasing ultraviolet-B (+UV-B) radiation ozone depletion (arctic ozone hole)\nIncreasing atmospheric CO2 (+CO2) anthropogenic emissions\nplants: UV-B potentially harmful, +CO2 potentially beneficial\nTherefore +CO2 alleviate UV-B damage impacts.HypothesisThe effect UV-B radiation growth depend levels CO2Predictions:+UV-B radiation reduce growth arctic plants\n+CO2 increase growth arctic plants\n+UV-B radiation impacts less +CO2What unique context, hypothesis, predictions?’s presentation CO2 UVB statement use words like “effect X alleviate impacts Y” words like “effects X less Y”. words phrases reflect context dependency effects treatment levels.Thus, restate introduced …. talk interactions, can rely simple vocabulary independent actual treatment levels: can always describe interaction like :effect X Y depends Z.orThe effect X Y varies Z.‘rubric’, Y response variable, X Z explanatory, independent variables. , example ,effect CO2 plant biomass yield depends UV-B radiation levels.ORthe effect CO2 plant biomass yield varies UV-B radiation levels.simple phrasing describes interaction.","code":""},{"path":"designs-for-testing-for-interactions-the-two-way-anova-and-factorial-designs..html","id":"numerical-example-for-emphasis","chapter":"6 Designs for testing for interactions: the two-way ANOVA and factorial designs.","heading":"6.1.1.1 Numerical example for emphasis","text":"Let’s imagine following situation. folowing three numbers call Main Effects:Control = 20g Yield\nUV-B = 10g Yield\nC02 = 29g YieldThese numbers allow us calculate Additive Effect, effect CO2 UV-B simply estimated adding two independent effects together:ADDITIVE RESULT: C02 + UV-B = 39g YieldHowever, additive outcome may happens. Imagine Synergy - effects sum independent effects - Antagonism - effects less expected one offsets .SYNERGISTIC RESULT: C02 + UV-B = 60g Yield\nANTAGONISTIC RESULT: C02 + UV-B = 19g Yield","code":""},{"path":"designs-for-testing-for-interactions-the-two-way-anova-and-factorial-designs..html","id":"the-factorial-design-why-study-interactions","chapter":"6 Designs for testing for interactions: the two-way ANOVA and factorial designs.","heading":"6.1.1.2 The Factorial Design: Why Study Interactions?","text":"UV-B C02 experiment thought two experiments – Control vs UV-B Control vs C02 experiment. combine get Factorial Experiment can actually estimate whether interaction, whether synergy antagonism. factorial design example, four treatment levels combinations treatments.ControlUV-BC02UV-B + C02Some may thinking simply treat treatment levels indepdently, unique treatments levels - e.g. one-way ANOVA. don’t. design analyse data collect two-way analysis - factorial design. Two-way ANOVA designFactorial treatments two main advantages 1-way approach.factors interact – effect C02 depends UV-B – can estimate interaction - dependency. One-way designs , can lead serious misunderstandings (assuming effect one thing depend ).Furthermore, factors DON’T interact, factorial designs precise (smaller error variance) estimating main (non-interacting effects) one-way designs experiments.Hence ALWAYS use factorial designs experimental design contains interaction (asking question includes word(s) depends varies !","code":""},{"path":"designs-for-testing-for-interactions-the-two-way-anova-and-factorial-designs..html","id":"a-factorial-design-and-the-two-way-anova","chapter":"6 Designs for testing for interactions: the two-way ANOVA and factorial designs.","heading":"6.2 A Factorial Design and the Two-Way ANOVA","text":"following dataset plantYield_factorial contains two observation columns - yield_ind data INTERACTION. yield_int data interaction. use showcase work 2-way ANOVA analysis factorial design.note data replication randomisation. four replicate plants/plots allocated randomly four treatment combinations.evidence factorial design","code":"\nxtabs(~UVB+CO2, data = plantYield_factorial)##       CO2\n## UVB    Con CO2+\n##   Con    4    4\n##   UVB+   4    4"},{"path":"designs-for-testing-for-interactions-the-two-way-anova-and-factorial-designs..html","id":"plot-the-factorial-design","chapter":"6 Designs for testing for interactions: the two-way ANOVA and factorial designs.","heading":"6.2.1 Plot the factorial design!","text":"combine dplyr magic (calculating means group - two grouping variables!), ggplot magic (adding lines connecting means top raw data) beauty patchwork, package plot layouts.goal plot data interaction next plot data interaction.Given ’ve read , able fill blanks:see left, pattern suggest effect ______ ________ vary ________.contrast, right pattern suggests effect ______ ________ ________ ________:","code":""},{"path":"designs-for-testing-for-interactions-the-two-way-anova-and-factorial-designs..html","id":"how-to-analyse-and-interpret-the-factorial-design","chapter":"6 Designs for testing for interactions: the two-way ANOVA and factorial designs.","heading":"6.2.2 How to analyse and interpret the factorial design","text":"plotting, now analyse data set.also make mistake analysing data interaction model specify interaction.thus making three models. model interaction data without specifying interaction, model interaction data without specifying interaction model interaction data interaction specified. second model incorrect, fitting helps illuminate fit interaction design contains potential interaction (factorial design).Important Note + * mean models. model specification, see CO2 + UVB CO2 * UVB. Using vocabulary , CO2 + UVB specifying independent additive effects. ANOVA table produced anova(), three lines: one CO2, one UVB one residuals. contrast, CO2 * UVB produces four lines output ANOVA table. say CO2 * UVB expands include main, independent effects CO2 UVB, also interaction . CO2 * UVB == CO2 + UVB + CO2:UVB last term interaction. Thus, four lines reported: one CO2, one UVB, one interaction one residuals.Let’s focus model 2 interpret . ANOVA table now multiple rows. saw block design. important thing note table now read sequentially. first note CO2 explains \\(507.19\\) units variation (Mean Sq) plant Yield. captured variation, note UVB captures \\(216.29\\) additional units. , capture variation caused directly CO2 UVB, now see interaction - asking whether effect CO2 varies UVB - explains additional \\(127.72\\) units. … \\(11.11\\) units unexplained variation.Great. , remember well calculate F-value. ANOVA (categorial variable) framework, F-value ratio variance explained factor relative residual variation. ’s F values come …. recall BIG F-values indicate variation allocated treatment levels, versus ’s left . bigger numerator value relative residual denominator, variation term explained.experimental design, like , one must remember actually single question, related independent main effects.relates interaction term: designed experiment test hypothesis effect CO2 yield varies UVB. single choice answer - yes . case, captured variation independent effect, still large amount variation captured ‘allowing’ effects vary . null hypothesis two variables interact (depend ), getting Mean square estimate \\(127.72\\) relative residual \\(11.11\\) unlikely. reject null!Spend time investigating happened model 2 model 3 recall ONE CORRECT, regardless whether data look like left right panel . Note differences outputs. Note infer model interaction data incorrectly.free lunch.must understand data question must fit model correctly matches design! case, really one model fit. model 2. EVEN data look like left panel, interaction, experiment designed test hypothesis effect CO2 varies UVB. can accept reject null hypothesis interaction fitting model 2. can guess right model picture. design dictates model. , can guess answer….","code":"\n# A Correct model with no interaction on data with no interaction\nint_mod_1 <- lm(yield_ind ~ CO2 + UVB, data = plantYield_factorial)\n\n# A Correct model with interaction where the should be an interaction\nint_mod_2 <- lm(yield_int ~ CO2 * UVB, data = plantYield_factorial)\n\n# THE WRONG MODEL: model without interaction, on data that should use the interaction\nint_mod_3 <- lm(yield_int ~ CO2 + UVB, data = plantYield_factorial)\n\nanova(int_mod_1) # Good model, no interaction in the data and none in the model## Analysis of Variance Table\n## \n## Response: yield_ind\n##           Df Sum Sq Mean Sq F value    Pr(>F)    \n## CO2        1 321.00  321.00  35.905 4.504e-05 ***\n## UVB        1 241.27  241.27  26.987 0.0001726 ***\n## Residuals 13 116.22    8.94                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nanova(int_mod_2) # Good model, interaction in the data and interaction in the model## Analysis of Variance Table\n## \n## Response: yield_int\n##           Df Sum Sq Mean Sq F value    Pr(>F)    \n## CO2        1 671.67  671.67 70.0311 2.364e-06 ***\n## UVB        1  56.75   56.75  5.9165   0.03159 *  \n## CO2:UVB    1  82.15   82.15  8.5654   0.01268 *  \n## Residuals 12 115.09    9.59                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nanova(int_mod_3) # Bad model, interaction in the data, but failure to specify in the model## Analysis of Variance Table\n## \n## Response: yield_int\n##           Df Sum Sq Mean Sq F value   Pr(>F)    \n## CO2        1 671.67  671.67  44.269 1.58e-05 ***\n## UVB        1  56.75   56.75   3.740  0.07519 .  \n## Residuals 13 197.24   15.17                     \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"designs-for-testing-for-interactions-the-two-way-anova-and-factorial-designs..html","id":"visreg-and-the-2-way-anova","chapter":"6 Designs for testing for interactions: the two-way ANOVA and factorial designs.","heading":"6.2.3 visreg and the 2-way ANOVA","text":"Don’t forget correct standard error ‘result’ residuals mean squared. can use dplyr + ggplot2 method, visreg estimate . use visreg package put figure next original ggplot interaction data. Either OK presentation, opt left panel. Note use correct model design question (model 2).","code":"\np3 <- visreg(int_mod_2,\"CO2\",by=\"UVB\", gg=TRUE) +\n  theme_classic()\n\np2+p3"},{"path":"interactions-part-2-introducing-the-ancova-analysis-of-covariance.html","id":"interactions-part-2-introducing-the-ancova-analysis-of-covariance","chapter":"7 Interactions Part 2: Introducing the ANCOVA (analysis of covariance)","heading":"7 Interactions Part 2: Introducing the ANCOVA (analysis of covariance)","text":"previous chapters, introduced classic experimental design principles, , focused revisiting 1-way ANOVA introduced 2-way ANOVA. models, explanatory variables categorical (factors). means explanatory variable distinct, discrete categories levels.many experiments, however, might combine categorical variable continuous variable. example, might estimate eggs produced function body size (continuous) season (categorical). might estimate effect mutagen (continuous) tumour formation wild type vs. genetically modified (categorical) fruit flies.simple examples describe ANCOVA, one explanatory variable continuous (e.g. body size mutagen) categorical (e.g. season fly-type). case, essentially combining ANOVA Regression model! recall regression largely estimating slopes intercepts, might think, hey, COOL, ANCOVA, can ask categorical variable alters slope ….. ’d correct.important understand core statement interactions change.effect X Y varies Z, translates ) effect body size egg production varies season; b) effect mutagen tumour formation varies fly-type.written like , previous statements slopes even clear. effect body size (continuous) egg production regression estimate slope. effect mutagen concentration tumour formation regression estimate slope. can ask whether slope different seasons fly-type.","code":""},{"path":"interactions-part-2-introducing-the-ancova-analysis-of-covariance.html","id":"what-this-chapter-covers.","chapter":"7 Interactions Part 2: Introducing the ANCOVA (analysis of covariance)","heading":"7.1 What this chapter covers.","text":"chapter focus ANCOVA, also touches additional concepts. primary foci thus:ANCOVA modeltransformationsplotting model results ’ve made transformations.","code":""},{"path":"interactions-part-2-introducing-the-ancova-analysis-of-covariance.html","id":"setting-up-the-various-ideas.","chapter":"7 Interactions Part 2: Introducing the ANCOVA (analysis of covariance)","heading":"7.2 Setting up the various ideas.","text":"Let’s start looking example effect Height Weight varies Sex. classic set data numerous organisms…. captures biologically question sexual dimorphism - relationship Height Weight (regression continuous variable Weight) vary Sex (categorical variable [e.g. ANOVA], case M/F can depending organism)?relationship can take many patterns.upper left see pattern Males heavier Females, effect Height Weight.upper right, see positive relationship Weight Height, differences Males Females.lower left, might argue positive relationship Weight Height, relationship Weight Height vary (slope ) Males heavier (red dots mostly blue)lower right, see evidence interaction - effect Height Weight (slopes), varies Sex.’s quite important recognise patterns (predictions) possible outcome testing null hypothesis. key thing remember priori (advance hypothesis) difference slopes males females. Regardless pattern, specify appropriate model test hypothesis answer question motivated design experiment data collection.Let’s super clear: data start fundamental question uses vocabulary used previous chapter - effect Height Weight vary Sex. data might look like one patterns. , one model syntax figure tests null hypothesis gives us chance evaluate predictions: lm(Weight ~ Height * Sex, data = data.frame.name).need refresher * symbol means, pop back chapter 5 explain fit models; also review .","code":""},{"path":"interactions-part-2-introducing-the-ancova-analysis-of-covariance.html","id":"anticipating-the-anova-table-for-an-ancova-model","chapter":"7 Interactions Part 2: Introducing the ANCOVA (analysis of covariance)","heading":"7.2.1 Anticipating the ANOVA table for an ANCOVA model","text":"Let us also recall sequential nature ANOVA table output. expect see, fit model, . contrast ANOVA, ANCOVA, see first estimate variation explained continuous variable, categorical variable finally, seeing report , estimate variation attributable interaction. Another way think follows (explore figures along ):estimate intercept slope, ignoring different categories, much variation explain.\nhappens let two lines, one category, slope (e.g. different intercepts, slope). explain variation?\nFinally, let two lines, different slopes (interaction exists) - explain additional variation?get last scenario, answer yes, options, different slopes capture variation response, evidence interaction.","code":""},{"path":"interactions-part-2-introducing-the-ancova-analysis-of-covariance.html","id":"working-through-an-ancova-example.","chapter":"7 Interactions Part 2: Introducing the ANCOVA (analysis of covariance)","heading":"7.3 Working through an ANCOVA example.","text":"Let’s work built dataset R - Davis Study, exactly data. associated assignment another example.process follow tried true approach analysing data. workflow fully embedded head now:PLOT DataBuild model test hypothesisCheck AssumptionsMake InferenceUpdate Figure Publication","code":""},{"path":"interactions-part-2-introducing-the-ancova-analysis-of-covariance.html","id":"organise-the-packages-and-get-the-data-and-make-your-picture","chapter":"7 Interactions Part 2: Introducing the ANCOVA (analysis of covariance)","heading":"7.3.1 Organise the packages and get the data and make your picture","text":"data using example dataset built R, embedded carData package, installed car package - download install can use following code (don’t forget tidyverse, agricolae, ggfortify, visreg etc).data blackboard site.Note also building script, need following packages: tidyverse, ggfortify, visreg, patchworkWhoa!… ’s going ? Well,massive justification say “always plot data” anything. looks like one data points height weight data entered incorrectly, wrong way around. ‘feature’ dataset. course go back master spreadsheet make corretion, good idea real life, let’s see fix using R. Let’s fix . Lets find row mistake looking height values <100, make switch.Excellent. Let’s look picture ask null hypothesis question: effect Height Weight vary Sex? think?can actually get bit help . can use ggplot magic help us make GUESS. Let’s use geom_smooth() help us guess answer.NOTE: statistics. using graphics help guide insight expectation outcome statistical test hypothesis., ‘proven’ anything tested hypothesis. good guess though. can guess thatMales heavier females (difference intercepts?)effect height weight positive (slope(s) positive, negative)might difference slopes - Male line looks steeper.might even go far estimate eye overall slope, assuming effect Sex. Recalling slope rise run change y change x, can guess slope ~ \\((100-40)/(200-140) = (60/60) = 1\\). Can guess slope Sex?","code":"\nlibrary(tidyverse)\nlibrary(ggfortify)\nlibrary(visreg)\nlibrary(patchwork)\n\n# this creates a working version of the davis data for you.\n# the carData:: syntax is a way to use this package without using\n# the library() function.\nDavis <- carData::Davis\n\n# check it out\nglimpse(Davis)## Rows: 200\n## Columns: 5\n## $ sex    <fct> M, F, F, M, F, M, M, M, M, M, M, F, F, F, F, F, M, F, M, F, M, …\n## $ weight <int> 77, 58, 53, 68, 59, 76, 76, 69, 71, 65, 70, 166, 51, 64, 52, 65…\n## $ height <int> 182, 161, 161, 177, 157, 170, 167, 186, 178, 171, 175, 57, 161,…\n## $ repwt  <int> 77, 51, 54, 70, 59, 76, 77, 73, 71, 64, 75, 56, 52, 64, 57, 66,…\n## $ repht  <int> 180, 159, 158, 175, 155, 165, 165, 180, 175, 170, 174, 163, 158…\n# make the most basic of exploratory plots.\nggplot(Davis, aes(x = height, y = weight, col = sex))+\n  geom_point()\n#which row? 12\nDavis %>% filter(height < 100)##    sex weight height repwt repht\n## 12   F    166     57    56   163\n# BASE R syntax to see each observation\nDavis$weight[12]## [1] 166\nDavis$height[12]## [1] 57\n# BASE R syntax to change the specific values in the specific row\nDavis$weight[12] <- 57\nDavis$height[12] <- 166\n\n# replot\nggplot(Davis, aes(x = height, y = weight, col = sex))+\n  geom_point()\nggplot(Davis, aes(x = height, y = weight, col = sex))+\n  geom_point()+\n  # add a best fit line to each group (the sex category)\n  geom_smooth(method = lm, se = FALSE)## `geom_smooth()` using formula 'y ~ x'"},{"path":"interactions-part-2-introducing-the-ancova-analysis-of-covariance.html","id":"building-the-model-and-understanding-it","chapter":"7 Interactions Part 2: Introducing the ANCOVA (analysis of covariance)","heading":"7.4 Building the model (and understanding it)","text":"next step build model test hypothesis. declared , model test interaction lm(weight ~ height * sex, data = Davis). Let’s discuss bit.First, described , Chapter 5, model * expands following full model two main effects interaction:lm(weight ~ height + sex + height:sex, data = Davis)reads “weight function effect height (slope), sex (intercept) interaction height sex (slopes vary?). height * aex syntax always expands full model - model containing main effects interaction.OK. Let’s fit modelThat’s . ’ve got model. make attempts actually evaluating test hypothesis, check assumptions!, use autoplot function ggfortify package.OK. Let’s walk three core diagnostics.upper left, evaluating systematic part model - systematic departures linear model ’ve speficied? interactions missing specific non-linearities? Nope.upper right, evaluating normality residuals. look pretty good. notice, event though deviations, pattern deviations move away line ‘come back’ ends. typical normally distributed residuals.lower left, evaluating assumption constant mean-variance relationship. Oops. Remember, expecting something show trend . Even without panic lines, looks like variance (y-axis) increasing mean (x-axis).","code":"\n# we call the model mod_Davis.\nmod_Davis <- lm(weight ~ height*sex, data = Davis)\nautoplot(mod_Davis)"},{"path":"interactions-part-2-introducing-the-ancova-analysis-of-covariance.html","id":"dealing-with-the-mean-variance-breakdown.","chapter":"7 Interactions Part 2: Introducing the ANCOVA (analysis of covariance)","heading":"7.4.1 Dealing with the mean-variance breakdown.","text":"issue one can deal via transformation.Let’s start facts…. variance increases mean, transformation can work logarithm continuous variables.short section (APS 240 reading)[https://dzchilds.github.io/stats--bio/data-transformations.html#trans-types] explore. Please read summary transformations, bookmark future. handy.question routinely comes whether transformations ‘changing data’. Rather focusing , offer following interpretation. Linear models fit lm() carry set assumptions (focus three panels using autoplot). met, can trust inference (F-testing).biological data unlikely conform perfectly assumptions, experience shown (fortunately) t-tests, ANOVAs regressions generally quite robust—perform reasonably well data deviate extent assumptions tests. However, cases residuals clearly far normal, variances change lot across groups - (APS 240)[https://dzchilds.github.io/stats--bio/data-transformations.html#transforms-introduction].real problems, can use transformations. ‘change data’ instead, retain relationships data points, put everything difference scale can use power linear model answer question. tricky thing report insights reader back original ‘response’ scale. ’ll get . rest assured, transformations don’t change data., data transform continuous variables - continuous response variable continuous explanatory variable.OK. patterns still . let’s see happens model assumptions now!scale-location plot definitely flatter - can tell range y-axis scale-location plot. , transformation, can now move evaluating model. probably thinking means analyse data log-log axis…. come shortly.","code":"\n# re-plot with log-log\nggplot(data = Davis, aes(x = log(height), y = log(weight), col = sex))+\n  geom_point()+\n  geom_smooth(method = lm, se = FALSE)## `geom_smooth()` using formula 'y ~ x'\n# fit the model - note we can specify the transformation RIGHT IN THE MODEL\nmod_Davis_log <- lm(log(weight) ~ log(height) * sex, data = Davis)\n\n# check the new residuals\nautoplot(mod_Davis_log)"},{"path":"interactions-part-2-introducing-the-ancova-analysis-of-covariance.html","id":"making-inference-on-the-ancova","chapter":"7 Interactions Part 2: Introducing the ANCOVA (analysis of covariance)","heading":"7.4.2 Making inference on the ANCOVA","text":"next step use detail ANOVA table - yes, use anova() function build anova table explore results ANCOVA.Let’s revisit initial guesses work model telling us:Males heavier females (difference intercepts?)effect height weight positive (slope(s) positive, negative)might difference slopes - Male line steeper.Together, graph guesses lead feeling effect height weight varies sex.Howwever…. table tells us evidence interaction. last line table contains p-value interaction. testing null hypothesis slopes . can reject null hypothesis. evidence allowing slopes Males Females different supported. ’s answer guess 3 . also answer question: effect Height Weight vary Sex. Nope.However, detect main effects height sex. means effect - say effects additive.Great. means data, despite pattern eye sees, can distinguished pattern picture lower left.slope associated Height (don’t know whether ’s positive , think ), effect sex (don’t know whether Males heavier yet). can say, confidence, .effect height weight vary sex (F = 1.01, df = 1,196, p = 0.29). effect sex (F, df, p) height (F, df, p) thus additive Weight.Let’s work sequentially read table now:allow common slope associated log(Height), capture \\(4.66\\) units variation log(weight), compared \\(0.013\\) units variation left (residual MSE), lot. F-value thus BIG p-value small. allow effect Sex define different average log(weight), important captures \\(0.344\\) units variation, comparied \\(0.013\\) units residual, also big (Big F, small P).However, allow slopes caused log(height) vary sex, captures little additional variation respect residual variation (\\(0.014\\) comprared \\(0.013\\)) hence small F large P term.","code":"\nanova(mod_Davis_log)## Analysis of Variance Table\n## \n## Response: log(weight)\n##                  Df Sum Sq Mean Sq  F value    Pr(>F)    \n## log(height)       1 4.6643  4.6643 357.4735 < 2.2e-16 ***\n## sex               1 0.3446  0.3446  26.4115 6.647e-07 ***\n## log(height):sex   1 0.0144  0.0144   1.1038    0.2947    \n## Residuals       196 2.5574  0.0130                       \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"interactions-part-2-introducing-the-ancova-analysis-of-covariance.html","id":"the-summary-table-the-actual-slopes-and-making-sense-of-the-log-stuff.","chapter":"7 Interactions Part 2: Introducing the ANCOVA (analysis of covariance)","heading":"7.4.3 The summary table, the actual slopes and making sense of the log stuff.","text":"Let’s start investigating details via summary table:table reports treatment contrasts introduced earlier semester. Let’s walk details.first two rows correspond one sexes. Can identify one? hint looking rows. M . M comes F (F first alphabet). first two rows correspond intercept slope Females.may asking intercept negative number. simple look back range x-axis answer … y intercept occurs x = 0, right?understand, principles equation line, following:effect height weight females log(weightF) = -5.32 + 1.82*log(heightF).OK… let’s interpret next two lines mean. third line labelled SexM. fourth labelled logHeight:SexM. guesses associated slope intercept?One trick, , recognise syntax -> presence : indicative interaction thing lets slopes vary. , SexM intercepts logHeight:SexM slopes. ?Recall previous work treatment contrasts DIFFERENCES. Thus, sexM term difference female male intercept! logHeight:SexM difference female male slopes!allows following maths worked ….log(weightF) = -5.32 + 1.82*log(heightF)log(weightM) = (-5.32-2.37) + (1.82+0.48)*(log(heightF))However, know \\(0.48\\) increase slope signficant, result, -2.37 increase intercept moving Female Male also significant change","code":"\nsummary(mod_Davis_log)## \n## Call:\n## lm(formula = log(weight) ~ log(height) * sex, data = Davis)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -0.29310 -0.06543 -0.00592  0.07420  0.43410 \n## \n## Coefficients:\n##                  Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)       -5.3202     1.6016  -3.322  0.00107 ** \n## log(height)        1.8329     0.3138   5.841 2.13e-08 ***\n## sexM              -2.3724     2.3765  -0.998  0.31936    \n## log(height):sexM   0.4852     0.4618   1.051  0.29473    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.1142 on 196 degrees of freedom\n## Multiple R-squared:  0.6626, Adjusted R-squared:  0.6575 \n## F-statistic: 128.3 on 3 and 196 DF,  p-value: < 2.2e-16"},{"path":"interactions-part-2-introducing-the-ancova-analysis-of-covariance.html","id":"specifying-the-equations-supported-by-the-model.","chapter":"7 Interactions Part 2: Introducing the ANCOVA (analysis of covariance)","heading":"7.4.4 Specifying the equations supported by the model.","text":"order identify equations supported model - e.g. equations associated estimation teo lines different intercepts slope, can refit model reflect ADDITIVE effects , replacing * +.Right, now get expected pattern intercepts different slope :log(weightF) = -6.46 + 2.05*log(heightF)log(weightM) = (-6.46 + 0.12) + 2.05*log(heightF)can see common slope slightly higher average weight (\\(0.12\\) units!) males.","code":"\nmod_Davis_log2 <- lm(log(weight) ~ log(height) + sex, data = Davis)\nsummary(mod_Davis_log2)## \n## Call:\n## lm(formula = log(weight) ~ log(height) + sex, data = Davis)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -0.28714 -0.06906 -0.00978  0.07615  0.43717 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept) -6.46349    1.17541  -5.499 1.18e-07 ***\n## log(height)  2.05688    0.23030   8.931 2.99e-16 ***\n## sexM         0.12417    0.02417   5.138 6.66e-07 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.1143 on 197 degrees of freedom\n## Multiple R-squared:  0.6607, Adjusted R-squared:  0.6573 \n## F-statistic: 191.8 on 2 and 197 DF,  p-value: < 2.2e-16"},{"path":"interactions-part-2-introducing-the-ancova-analysis-of-covariance.html","id":"making-even-more-inference-and-drawing-the-picture","chapter":"7 Interactions Part 2: Introducing the ANCOVA (analysis of covariance)","heading":"7.4.5 Making even more inference and drawing the picture","text":"OK, lets use variation plotting tricks regression module (week 6) get nice picture.can see fourth column now…. predictions (also known fitted values) log(weight) function log(height) using additive model, originally measured height values data frame.can actually use data frame generate picture represents output statistical model.Great. Now can see full model (mod_Davis_log) told us. lines parallel. interaction. fact, can bit . Remember model saysFor women \\(log(weight)= -6.46 + 2.05 * log(height)\\)\nmen \\(log(weight)= (-6.46 + 0.12) + 2.05 * log(height)\\)log land, can clever maths: know \\(log(weight Female) - log(weight Male) = - 0.12\\)(treatment contrast intercept). also know (please memorise) difference logs equal log ratio:\\(log(weightF/weightM) = -0.12\\)Finally, can convert sides non-log exponentiating:\\(exp(log(weightF/weightM)) = exp(-0.12) = 0.88\\)mean? given height, female weight 88% males (e.g. 12% lower). Cool! ’s one benefits log-log linear relationships. ratio categories log-log land directly translates percent difference groups. ’s also worth noting height slope ~2, suggests… yes… log-land, weight scales \\(height^2\\).","code":"\n# first create a data frame to use that combines the raw data\n# with the predictions from the model.\n\n# note that the model is the ADDITIVE model, for plotting\n# step 1: make a copy of the raw data\n# step 2: use mutate to add the fitted values (at each value of height (x-axis) where we have measured data)\nplotThis <- Davis %>%\n  # ... a column of numbers of predicted weight using the model\n  mutate(predWeight = predict(mod_Davis_log2))\n\n# check it out.\nhead(plotThis)##   sex weight height repwt repht predWeight\n## 1   M     77    182    77   180   4.364677\n## 2   F     58    161    51   159   3.988326\n## 3   F     53    161    54   158   3.988326\n## 4   M     68    177    70   175   4.307379\n## 5   F     59    157    59   155   3.936578\n## 6   M     76    170    76   165   4.224381\n# Step 3: make a figure with lines from the model predictions\n# Step 4: add the raw data points from the original dataset\n# NOTE! pay attention to where we are using log()!\nggplot(plotThis, aes(x = log(height), y = predWeight, col = sex))+\n  geom_line()+\n  # now add the raw data note\n  geom_point(aes(x = log(height), y = log(weight)))"},{"path":"interactions-part-2-introducing-the-ancova-analysis-of-covariance.html","id":"some-general-principles-for-anova-and-ancova-modelling.","chapter":"7 Interactions Part 2: Introducing the ANCOVA (analysis of covariance)","heading":"7.5 Some General Principles for ANOVA and ANCOVA modelling.","text":"","code":""},{"path":"interactions-part-2-introducing-the-ancova-analysis-of-covariance.html","id":"ancova-and-2-way-anova-is-always-comparing-the-interaction-model-against-the-additive-model","chapter":"7 Interactions Part 2: Introducing the ANCOVA (analysis of covariance)","heading":"7.5.1 ANCOVA (and 2-way ANOVA) is always comparing the interaction model against the additive model!","text":"figure highlights various lm() models interpretations/assumptions associated pieces ANCOVA dataset. way envision potential linear relationships among variables might arise experiment continuous categorical explanatory variable.Note just data looks like particular pattern doesn’t mean use model. statistical model driven question original design.\nFigure 7.1: Getting Started R, 2nd Edition, OUP\nexample, design study ANCOVA question mind, always starting analysis question whether effect X Y varies Z. Thus, ANCOVA always starts comparing interaction (model E) additive model (model D).Proof: compare additive model model interaction, specifically testing whether allowing slopes vary sex explains additional variation beyond main, additive effects height sex. , use anova() function, pass two models instead one! called Liklihood Ratio Test comparing two models. Remembering difference * model + model just presence/absence interaction term, anova() comparison evaluates much variation explained interaction, additive effects modelled. follow code, compare result first test last line second. proves fit model E, test interaction actually comparison model E model D!","code":"\nanova(mod_Davis_log, mod_Davis_log2)## Analysis of Variance Table\n## \n## Model 1: log(weight) ~ log(height) * sex\n## Model 2: log(weight) ~ log(height) + sex\n##   Res.Df    RSS Df Sum of Sq      F Pr(>F)\n## 1    196 2.5574                           \n## 2    197 2.5718 -1 -0.014402 1.1038 0.2947\nanova(mod_Davis_log)## Analysis of Variance Table\n## \n## Response: log(weight)\n##                  Df Sum Sq Mean Sq  F value    Pr(>F)    \n## log(height)       1 4.6643  4.6643 357.4735 < 2.2e-16 ***\n## sex               1 0.3446  0.3446  26.4115 6.647e-07 ***\n## log(height):sex   1 0.0144  0.0144   1.1038    0.2947    \n## Residuals       196 2.5574  0.0130                       \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"interactions-part-2-introducing-the-ancova-analysis-of-covariance.html","id":"a-few-parting-tricks-about-specifying-models-in-r","chapter":"7 Interactions Part 2: Introducing the ANCOVA (analysis of covariance)","heading":"7.6 A few parting tricks about specifying models in R","text":"can add terms\nweight ~ sex + heightHave can crossed terms (interactions)\nweight ~ sex * height weight ~ sex +  height + sex : heightWe can remove terms\nweight ~ sex * height – sex : height weight~ sex +  heightWe can specify interations order k among 2 terms:\nweight~ (sex + height + age)^2 expands sex + height + age + sex : height + sex : age + age : height (e.g. two way interactions among three variables)","code":""}]
