<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 5 Design and Analysis of Experiments | An Introduction to Experimental Design ANOVA and ANCOVA</title>
<meta name="author" content="Andrew P Beckerman (with support from text and slides from Mark Rees and Gareth Phoenix)">
<meta name="description" content="In this section we are going to learn about how to implement two experimental designs: CRD: the completely randomised design CRBD: the completely randomised block design. These two designs are...">
<meta name="generator" content="bookdown 0.30 with bs4_book()">
<meta property="og:title" content="Chapter 5 Design and Analysis of Experiments | An Introduction to Experimental Design ANOVA and ANCOVA">
<meta property="og:type" content="book">
<meta property="og:description" content="In this section we are going to learn about how to implement two experimental designs: CRD: the completely randomised design CRBD: the completely randomised block design. These two designs are...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 5 Design and Analysis of Experiments | An Introduction to Experimental Design ANOVA and ANCOVA">
<meta name="twitter:description" content="In this section we are going to learn about how to implement two experimental designs: CRD: the completely randomised design CRBD: the completely randomised block design. These two designs are...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.0/transition.js"></script><script src="libs/bs3compat-0.4.0/tabs.js"></script><script src="libs/bs3compat-0.4.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">An Introduction to Experimental Design ANOVA and ANCOVA</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="readings--.html"><span class="header-section-number">2</span> Readings —-</a></li>
<li><a class="" href="introduction-to-experimental-design.html"><span class="header-section-number">3</span> Introduction To Experimental Design</a></li>
<li><a class="" href="examples-and-challenge-questions.html"><span class="header-section-number">4</span> Examples and Challenge Questions</a></li>
<li><a class="active" href="design-and-analysis-of-experiments.html"><span class="header-section-number">5</span> Design and Analysis of Experiments</a></li>
<li><a class="" href="designs-for-testing-for-interactions-the-two-way-anova-and-factorial-designs..html"><span class="header-section-number">6</span> Designs for testing for interactions: the two-way ANOVA and factorial designs.</a></li>
<li><a class="" href="interactions-part-2-introducing-the-ancova-analysis-of-covariance.html"><span class="header-section-number">7</span> Interactions Part 2: Introducing the ANCOVA (analysis of covariance)</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="design-and-analysis-of-experiments" class="section level1" number="5">
<h1>
<span class="header-section-number">5</span> Design and Analysis of Experiments<a class="anchor" aria-label="anchor" href="#design-and-analysis-of-experiments"><i class="fas fa-link"></i></a>
</h1>
<p>In this section we are going to learn about how to implement two experimental designs:</p>
<ul>
<li>CRD: the completely randomised design</li>
<li>CRBD: the completely randomised block design.</li>
</ul>
<p>These two designs are valuable in dealing with two things that make it hard to make strong inference from experiments: <em>noise</em> and <em>counfounding effects</em>.</p>
<p>These unwated sources of variation comes in two forms (see <a href="https://dzchilds.github.io/stats-for-bio/principles-experimental-design.html#confounded-and-noisy-experiments">APS 240 reading</a>)</p>
<ol style="list-style-type: decimal">
<li><p>The first is <em>confounding variation</em>. This occurs when there are one or more other sources of variation that work in parallel to the factor we are investigating and make it hard, or impossible, to unambiguously attribute any effects we see to a single cause. Confounding variation is particularly problematic in observational studies because, by definition, we don’t manipulate the factors we’re interested in.</p></li>
<li><p>The second is <em>noise</em>. This describes variation that is unrelated to the factor we are investigating but adds variability to the results so that it is harder to see, and detect statistically, any effect of that factor. As noted above, much of experimental design is about improving our ability to account for noise in a statistical analysis.</p></li>
</ol>
<p>We will consider these together, as some of the techniques for dealing with them are be applicable to both. The primary tools for dealing with them are</p>
<ol style="list-style-type: decimal">
<li>randomisation</li>
<li>blocking</li>
<li>appropriate controls</li>
<li>additional treatments.</li>
</ol>
<p>In the following sections, we are going to focus on the first three. In doing so, we will also revisit how we make inference from 1-way ANOVA experiments and introduce a more generalised approach to making <em>contrasts</em> we want. If you recall from the 1-way ANOVA work you did in the previous module (Week 7), we learned about <em>treatment contrasts</em>, the default comparison of means to a reference level, and then the <em>Tukey test</em>, which makes all pairwise comparisons. Here will will find an intermediate zone.</p>
<div id="a-crd-completely-randomised-design-example" class="section level2" number="5.1">
<h2>
<span class="header-section-number">5.1</span> A CRD (Completely Randomised Design) Example<a class="anchor" aria-label="anchor" href="#a-crd-completely-randomised-design-example"><i class="fas fa-link"></i></a>
</h2>
<p>The experiment is about plant crop biomass yield under several herbicide treatments - the herbicide targets weeds and not our target plant (e.g. Glyphosate): a control and two herbicides, and a third treatment that is a placebo - applied water but no herbicide.</p>
<p>The data for this example are called <code>plantYield.csv</code>.</p>
<p>For each treatment, we have n = 30 plants in separate pots in standarised conditions.</p>
<p>Can you explain why we are using the placebo? Do you know the measurement and experimental unit? As this is a 1-way ANOVA, what is the baseline hypothesis? Given that there is a control and two herbicides, are there alternative hypotheses you might test?</p>
<p>Let’s look at the structure of the design. As hoped, we have 30 replicates of each treatment. The second view reveals that the replicates are allocated randomly among the replicate plants. There is no order to the values in the <code>treat</code> column.</p>
<pre><code>## treat
##    Cont   Herb1   Herb2 Placebo 
##      30      30      30      30</code></pre>
<pre><code>##    plots r   treat
## 1      1 1 Placebo
## 2      2 2 Placebo
## 3      3 1    Cont
## 4      4 3 Placebo
## 5      5 1   Herb2
## 6      6 2    Cont
## 7      7 1   Herb1
## 8      8 2   Herb2
## 9      9 3    Cont
## 10    10 4 Placebo</code></pre>
<p>We have now added data to this design in order to start doing statistics. The <em>TRUTH</em> of these data are that on average, the controls have a yield of 20, Herbicide 1 increases yield by 5, Herbicide 2 by 6 and the placebo by 1 unit. These data are also quite variable. The standard deviation around the yields is large. We are going to analyse these data and</p>
<ol style="list-style-type: decimal">
<li>see if we can recover these estimates of ‘known’ yield.</li>
<li>test the null hypothesis.</li>
<li>test the hypothesis that herbicides, on average, increase yield.</li>
<li>test whether the two herbicides are different.</li>
<li>test whether the placebo is different from the control.</li>
</ol>
<p>And there is the answer to one of the questions above!</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># look at the design now.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">plantYield</span><span class="op">)</span></span></code></pre></div>
<pre><code>##   plots r   treat      obs
## 1     1 1 Placebo 27.54449
## 2     2 2 Placebo 22.39018
## 3     3 1    Cont 18.23051
## 4     4 3 Placebo 19.79473
## 5     5 1   Herb2 23.46557
## 6     6 2    Cont 21.65736</code></pre>
<div id="the-dplyr-and-ggplot-pipeline-for-inference." class="section level3" number="5.1.1">
<h3>
<span class="header-section-number">5.1.1</span> The dplyr and ggplot pipeline for inference.<a class="anchor" aria-label="anchor" href="#the-dplyr-and-ggplot-pipeline-for-inference."><i class="fas fa-link"></i></a>
</h3>
<p>Now we can move to our standard data management and visualisation pipeline.</p>
<ol style="list-style-type: decimal">
<li>review the data (the <code>plantYield.csv</code> file contains the data)</li>
<li>sumamrise the data with dplyr - generate means and se’s for the treatments</li>
<li>visualise with ggplot2</li>
</ol>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># check the data</span></span>
<span><span class="co"># note</span></span>
<span><span class="co"># obs == yield</span></span>
<span><span class="co"># treat == treatment</span></span>
<span><span class="co"># r = replicate (there are 30 of each treatment)</span></span>
<span></span>
<span><span class="fu">glimpse</span><span class="op">(</span><span class="va">plantYield</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Rows: 120
## Columns: 4
## $ plots &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 1…
## $ r     &lt;int&gt; 1, 2, 1, 3, 1, 2, 1, 2, 3, 4, 5, 4, 6, 5, 3, 2, 6, 7, 8, 4, 5, 3…
## $ treat &lt;chr&gt; "Placebo", "Placebo", "Cont", "Placebo", "Herb2", "Cont", "Herb1…
## $ obs   &lt;dbl&gt; 27.54449, 22.39018, 18.23051, 19.79473, 23.46557, 21.65736, 26.5…</code></pre>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># let's force treat to be a factor.  This will make life easier later...</span></span>
<span><span class="va">plantYield</span> <span class="op">&lt;-</span> <span class="va">plantYield</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>treat <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">treat</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># summarise to get means and ses</span></span>
<span><span class="va">sumDat</span> <span class="op">&lt;-</span> <span class="va">plantYield</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">group_by</span><span class="op">(</span><span class="va">treat</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">summarise</span><span class="op">(</span></span>
<span>    <span class="co"># calculate the means</span></span>
<span>    meanYield <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">obs</span><span class="op">)</span>,</span>
<span>    <span class="co"># calculate the se</span></span>
<span>    seYield <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">obs</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu">n</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span><span class="co"># plot the raw data and the mean±se</span></span>
<span><span class="co"># start with the mean±se and then add the raw data</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="va">sumDat</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">treat</span>, y <span class="op">=</span> <span class="va">meanYield</span><span class="op">)</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span>size <span class="op">=</span> <span class="fl">5</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu">geom_errorbar</span><span class="op">(</span>data <span class="op">=</span> <span class="va">sumDat</span>, <span class="fu">aes</span><span class="op">(</span>ymin <span class="op">=</span> <span class="va">meanYield</span> <span class="op">-</span> <span class="va">seYield</span>, ymax <span class="op">=</span> <span class="va">meanYield</span><span class="op">+</span><span class="va">seYield</span><span class="op">)</span>,</span>
<span>                width <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span>data <span class="op">=</span> <span class="va">design</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">treat</span>, y <span class="op">=</span> <span class="va">obs</span><span class="op">)</span>, colour <span class="op">=</span> <span class="st">'red'</span>, alpha <span class="op">=</span> <span class="fl">0.3</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="Experimental-Design,-ANOVA-and-ANCOVA_files/figure-html/unnamed-chunk-10-1.png" width="672"></div>
<p>A few things to notice.</p>
<ol style="list-style-type: decimal">
<li>The data are quite variable and the means of the herbicide treatments are roughly 5 and 6 units higher than the control. GOOD. This is as we expected….</li>
<li>The standard errors are quite small, even though the variation is large! Why is that!?</li>
<li>The two herbicides don’t look very different, especially given the variation around each treatment. Neither do the placebo and control. We need some stats.</li>
<li>For those of you interested in some extra reading and thinking, the 95% Confidence Interval around the means can be calculated using <span class="math inline">\(1.96*SE` == `1.96*sd(obs)/sqrt(n())\)</span>. Go ahead and do that and look into that if you want…</li>
</ol>
</div>
<div id="the-one-way-anova." class="section level3" number="5.1.2">
<h3>
<span class="header-section-number">5.1.2</span> The One-Way ANOVA.<a class="anchor" aria-label="anchor" href="#the-one-way-anova."><i class="fas fa-link"></i></a>
</h3>
<p>If you’ve been paying attention, we’ve essentially designed and plotted the data for a 1-way ANOVA. These data are very similar to the daphnia parasite data we finished semester 1 with.</p>
<p>To analyse these data, we use the <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> function to build the model, check assumptions, and then make inference. Let’s go.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># the model</span></span>
<span><span class="va">modYield</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">obs</span> <span class="op">~</span> <span class="va">treat</span>, data <span class="op">=</span> <span class="va">plantYield</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># assumptions</span></span>
<span><span class="fu">autoplot</span><span class="op">(</span><span class="va">modYield</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="Experimental-Design,-ANOVA-and-ANCOVA_files/figure-html/unnamed-chunk-11-1.png" width="672"></div>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># inference: anova</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">modYield</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: obs
##            Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## treat       3 807.49 269.164  33.257 1.383e-15 ***
## Residuals 116 938.85   8.094                      
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># contrasts</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">modYield</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = obs ~ treat, data = plantYield)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.6952 -2.1542 -0.3872  1.8383  7.0609 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   20.0004     0.5194  38.506  &lt; 2e-16 ***
## treatHerb1     4.1655     0.7346   5.671 1.06e-07 ***
## treatHerb2     6.2449     0.7346   8.502 7.43e-14 ***
## treatPlacebo   0.4832     0.7346   0.658    0.512    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 2.845 on 116 degrees of freedom
## Multiple R-squared:  0.4624, Adjusted R-squared:  0.4485 
## F-statistic: 33.26 on 3 and 116 DF,  p-value: 1.383e-15</code></pre>
</div>
<div id="making-insight-and-inference" class="section level3" number="5.1.3">
<h3>
<span class="header-section-number">5.1.3</span> Making insight and inference<a class="anchor" aria-label="anchor" href="#making-insight-and-inference"><i class="fas fa-link"></i></a>
</h3>
<p>Lets walks through things very discretely.</p>
<ol style="list-style-type: decimal">
<li>Our graph suggests that herbicide treatments have an effect of increasing yield.</li>
<li>Our model is designed to test this hypothesis - are any of the differences among means non-zero?</li>
<li>Our hypothesis is probably really about whether the herbicide and placebos are different than the controls. All Hail the <em>treatment contrast</em>!</li>
<li>Our diagnostics are fantastic… the best you’ve ever seen.</li>
<li>The Anova Table confirms that there are differences - we can reject the null hypothesis</li>
<li>The summary table confirms that Herb1 and Herb2 are both larger than controls and the Placebo is not.</li>
</ol>
<p>How do we interpret even more?</p>
<p>The estimate associated with Control is 20! Just where it should be.</p>
<p>The estimates associated with Herb1, Herb2 and Placebo are the differences between the mean of these treatments and the control (the reference level!). These differences are positive for Herb1 and Herb2, close to 5 and 6 respectively (as expected) and this positive difference is not 0 via the statistical test.</p>
<p>However, the difference for Placebo is close to 0 and therefore we can not reject the null hypothesis test that it differs from control. GENUIS!</p>
</div>
</div>
<div id="a-priori-vs.-post-hoc-contrasts" class="section level2" number="5.2">
<h2>
<span class="header-section-number">5.2</span> A priori vs. Post-Hoc Contrasts<a class="anchor" aria-label="anchor" href="#a-priori-vs.-post-hoc-contrasts"><i class="fas fa-link"></i></a>
</h2>
<p>As we discussed above, there are likely several other questions we might have wanted to answer when designing this experiment. For example, are the two herbicides different in their effects?</p>
<div id="custom-contrasts-versus-the-tukey-test" class="section level3" number="5.2.1">
<h3>
<span class="header-section-number">5.2.1</span> Custom contrasts versus the Tukey Test<a class="anchor" aria-label="anchor" href="#custom-contrasts-versus-the-tukey-test"><i class="fas fa-link"></i></a>
</h3>
<p>In the semester 1, we introduced how to do a Tukey Test. This is known as an <em>a posteriori</em> test – testing the significance of things suggested by the experiment, also known as data snooping or data dredging. These are multiple comparison methods (Bonferroni, Scheffe method, Tukey honest significant difference, Duncan’s multiple range test) which try to control the chance of getting a significant result by chance.</p>
<p>To understand the risks of these, consider this experimental design. We have 7 treatments. With 7 treatments, there are 21 pairwise comparisons. With p-value threshold of <span class="math inline">\(0.05\)</span> we expect 1/20 (5/100) tests to be significant. So with this 7 treatment and 21 comparison design, would you expect a signficant result by chance? You betyja.</p>
<p>This is why, unless a priori (in advance) you can justify ALL pairwise comparisons, a Tukey Test may not be appropriate.</p>
<p>Some statisticians really don’t like them:</p>
<blockquote>
<p>“In my view multiple comparison methods have no place at all in the interpretation of data” -Nelder (a very very very well respected statistician).</p>
</blockquote>
<div id="the-more-appropriate-approach---custom-contrasts" class="section level4" number="5.2.1.1">
<h4>
<span class="header-section-number">5.2.1.1</span> The more appropriate approach - custom contrasts<a class="anchor" aria-label="anchor" href="#the-more-appropriate-approach---custom-contrasts"><i class="fas fa-link"></i></a>
</h4>
<p>The <em>more appropriate</em> approach is to specify <em>a priori</em> (before the experiment) a set of hypotheses you want to test, and then test them using contrasts.</p>
<p>For our experiment, as noted above, we were probably interested in what our treatment contrasts provided - tests of difference with the control. But we had a few others too.</p>
<p>Specifying specific contrasts is easy once you get your head around the ‘structure’ of the syntax.</p>
<p>Lets have a go with specifying a comparison JUST between Herbicide 1 and the control. Remember that your model is called <code>modYield</code> and your data is called <code>design</code>.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># check the levels and ORDERING of the treatments</span></span>
<span><span class="co"># this function, levels(), tells you this</span></span>
<span><span class="co"># note the ORDER: it is alphabetical, and control comes first</span></span>
<span><span class="co"># the words fill in four slots c(X,X,X,X). </span></span>
<span><span class="co"># we will use these slots....</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/levels.html">levels</a></span><span class="op">(</span><span class="va">plantYield</span><span class="op">$</span><span class="va">treat</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] "Cont"    "Herb1"   "Herb2"   "Placebo"</code></pre>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># define the contrast you want using -1, 1 and 0's</span></span>
<span><span class="co"># this says compare control with herbicide 1.... and ignore the Herb2 and Placebo</span></span>
<span><span class="co"># we give the reference -1 to the control slot</span></span>
<span><span class="co"># and the reference 1 to the Herbicide 1 slot.</span></span>
<span><span class="va">contrast</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>,<span class="fl">1</span>,<span class="fl">0</span>,<span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># use the fit.contrast function from gmodels</span></span>
<span><span class="fu">fit.contrast</span><span class="op">(</span><span class="va">modYield</span>, <span class="st">"treat"</span>, <span class="va">contrast</span><span class="op">)</span></span></code></pre></div>
<pre><code>##                      Estimate Std. Error t value     Pr(&gt;|t|)
## treat c=( -1 1 0 0 ) 4.165507   0.734555 5.67079 1.058335e-07
## attr(,"class")
## [1] "fit_contrast"</code></pre>
<p>So, this says that the difference between the control and Herbicide 1 is ~5 and that this is different from 0. Does that number <code>4.16</code> look familiar? It should. It is the same number from the <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> table of the full model. This is because we just specified one of the three treatment contrasts that <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> uses.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># remind ourselves of the contrast from the summary table</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">modYield</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = obs ~ treat, data = plantYield)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.6952 -2.1542 -0.3872  1.8383  7.0609 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   20.0004     0.5194  38.506  &lt; 2e-16 ***
## treatHerb1     4.1655     0.7346   5.671 1.06e-07 ***
## treatHerb2     6.2449     0.7346   8.502 7.43e-14 ***
## treatPlacebo   0.4832     0.7346   0.658    0.512    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 2.845 on 116 degrees of freedom
## Multiple R-squared:  0.4624, Adjusted R-squared:  0.4485 
## F-statistic: 33.26 on 3 and 116 DF,  p-value: 1.383e-15</code></pre>
</div>
<div id="a-different-contrast---herbicide-1-vs-herbicide-2." class="section level4" number="5.2.1.2">
<h4>
<span class="header-section-number">5.2.1.2</span> A different contrast - Herbicide 1 vs Herbicide 2.<a class="anchor" aria-label="anchor" href="#a-different-contrast---herbicide-1-vs-herbicide-2."><i class="fas fa-link"></i></a>
</h4>
<p>If we want to compare the two herbicides we can use this approach. Note in advance that this contrast DOES NOT exist in the summary table!</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># define the contrast you want using -1, 1 and 0's</span></span>
<span><span class="co"># this says compare herb1 with herb2, ignoring the control and placebo.</span></span>
<span><span class="co"># we give the slot for herbicide 1 a "-1" and the slot for herbicide 2 a "1".</span></span>
<span><span class="va">contrast</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="op">-</span><span class="fl">1</span>,<span class="fl">1</span>,<span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># use the fit.contrast function from gmodels</span></span>
<span><span class="fu">fit.contrast</span><span class="op">(</span><span class="va">modYield</span>, <span class="st">"treat"</span>, <span class="va">contrast</span><span class="op">)</span></span></code></pre></div>
<pre><code>##                      Estimate Std. Error  t value    Pr(&gt;|t|)
## treat c=( 0 -1 1 0 ) 2.079439   0.734555 2.830882 0.005473189
## attr(,"class")
## [1] "fit_contrast"</code></pre>
<p>Isn’t this cool? And quite surprising, right? We did not expect this. This says that despite the difference we created of ~1 unit of yield between Herb1 and Herb2, and even with the big variation, the statistics detect a significant difference.</p>
<p>Note that the difference reported is the difference between the two means that we calcuated from the sumDat calculation above!:</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># check our summary data</span></span>
<span><span class="va">sumDat</span></span></code></pre></div>
<pre><code>## # A tibble: 4 × 3
##   treat   meanYield seYield
##   &lt;fct&gt;       &lt;dbl&gt;   &lt;dbl&gt;
## 1 Cont         20.0   0.552
## 2 Herb1        24.2   0.591
## 3 Herb2        26.2   0.359
## 4 Placebo      20.5   0.544</code></pre>
<p>Here it is: <span class="math inline">\(26.2 - 24.2 = 2\)</span></p>
</div>
<div id="a-more-complex-contrast-comparing-the-average-of-the-herbicide-effect-with-the-control." class="section level4" number="5.2.1.3">
<h4>
<span class="header-section-number">5.2.1.3</span> A more complex contrast: comparing the average of the herbicide effect with the control.<a class="anchor" aria-label="anchor" href="#a-more-complex-contrast-comparing-the-average-of-the-herbicide-effect-with-the-control."><i class="fas fa-link"></i></a>
</h4>
<p>This might be a comparison you intended to make also… the average effect of herbicides in general. To do this, we expand the idea of -1,1 and 0’s to include 1/2s (yes, 1/3’s and more are possible):</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># define the contrast you want using -1, 1 and 0's</span></span>
<span><span class="co"># this says compare control with the average of herbicide 1 and 2, ignoring the placebo</span></span>
<span><span class="co"># we give the control slot a -1 and the two herbicide slots a 1/2 each.</span></span>
<span><span class="va">contrast</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">/</span><span class="fl">2</span>, <span class="fl">1</span><span class="op">/</span><span class="fl">2</span>, <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># use the fit.contrast function from gmodels</span></span>
<span><span class="fu">fit.contrast</span><span class="op">(</span><span class="va">modYield</span>, <span class="st">"treat"</span>, <span class="va">contrast</span><span class="op">)</span></span></code></pre></div>
<pre><code>##                          Estimate Std. Error  t value     Pr(&gt;|t|)
## treat c=( -1 0.5 0.5 0 ) 5.205226  0.6361433 8.182475 4.015904e-13
## attr(,"class")
## [1] "fit_contrast"</code></pre>
<p>How very cool. This custom contrast delivers the inference that herbicides on average increase yield by five units.</p>
<p>Again, checking sumDat, we can see where this result comes from.</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">sumDat</span></span></code></pre></div>
<pre><code>## # A tibble: 4 × 3
##   treat   meanYield seYield
##   &lt;fct&gt;       &lt;dbl&gt;   &lt;dbl&gt;
## 1 Cont         20.0   0.552
## 2 Herb1        24.2   0.591
## 3 Herb2        26.2   0.359
## 4 Placebo      20.5   0.544</code></pre>
<p><span class="math inline">\((24.2+26.2)/2 = 25.2\)</span> –&gt; <span class="math inline">\(25.2 - 20 = 5.2\)</span></p>
</div>
</div>
<div id="the-write-up-using-contrasts." class="section level3" number="5.2.2">
<h3>
<span class="header-section-number">5.2.2</span> The Write Up using contrasts.<a class="anchor" aria-label="anchor" href="#the-write-up-using-contrasts."><i class="fas fa-link"></i></a>
</h3>
<p>Fill in these blanks using the various contrasts you made above!</p>
<blockquote>
<p>We conclude that herbicides on average cause an _____ gram increase in yield (t = ___ , p = ___ ). We also note that there was a significant difference of _____ grams between the herbicides (t = _____ p = ______). The additional placebo treatment had no effect on yield (t = _______ p = __________).</p>
</blockquote>
</div>
<div id="coming-back-to-randomisation" class="section level3" number="5.2.3">
<h3>
<span class="header-section-number">5.2.3</span> Coming Back to Randomisation<a class="anchor" aria-label="anchor" href="#coming-back-to-randomisation"><i class="fas fa-link"></i></a>
</h3>
<p>We have worked here with a CRD where the measurement units are completely randomised to the experimental treatments. This simple effort is super valuable. As you’ve read.</p>
<blockquote>
<p>Randomisation guards against a variety of possible biases and confounding effects, including the inadvertent biases that might be introduced simply in the process of setting up an experiment…. Randomisation is a critical method for guarding against confounding effects. It is the best insurance we have against unwittingly getting some other factor working in parallel to a treatment.</p>
</blockquote>
<p>But what if we know there is a gradient, or a feature of the environment or lab system that we KNOW could confound the design. Is there any way we can remove this known pattern? Yes…. of course there is.</p>
</div>
</div>
<div id="the-rcbd---the-randomised-complete-block-design" class="section level2" number="5.3">
<h2>
<span class="header-section-number">5.3</span> THE RCBD - The Randomised Complete Block Design<a class="anchor" aria-label="anchor" href="#the-rcbd---the-randomised-complete-block-design"><i class="fas fa-link"></i></a>
</h2>
<p>Blocking allows us to reduce known experimental error.</p>
<p>A block is a group of experimental units that are homogeneous in some sense – in the same place, or measured at the same time, or by the same person. They may experience a similar temperature, or hormone concentration. They may simply be a position in the incubator where light varies from front to back.</p>
<p>So when constructing blocks we try and select experimental units that are homogeneous within blocks but where the blocks, and thus units within them, may be dissimilar.</p>
<p>Why block? When we use a completely randomised design, the location or timing of our treatment ‘plots’ (patches with different N or soil-moisture, incubators, locations in a 96 well plate) can generate <em>heterogeneity</em> in experimental error (variation).</p>
<p>This has consequences for our ability to detect effects. As the variance of the Experimental Error increases, confidence intervals get wider and the power of our analysis decreases - it’s harder to detect effects of our treatments against the background noise. Ideally we would like to use experimental units that are homogeneous so the experimental error will be small. Blocking does this.</p>
<p>The simplest blocked design is the <strong>Randomized Complete Block design (RCB)</strong></p>
<p>We have one complete set of treatments in each block. For the sake of example, lets imagine we identify three ‘blocks’ - soil moisture zones. In the design above, we would allocate 10/30 replicates of each treatment to each block.</p>
<p>In the first block, we randomly assign the 10 treatments to n locations in the block. We do an <em>independent randomization</em> in each block. This is the RCB design.</p>
<p>For example, consider the following matrix: the rows are the blocks, the letters the different treatments. In each block, each treatment is represented, but it is in a different location in the block (randomisation of the g treatments in the n units). The blocks are in a sequence - left to right - this could be different days, different locations or different positions on a hillside, for example representing an elevation or soil moisture gradient.</p>
<p>The Blocks are designed to ‘capture’ that underlying source of variability and allow us to detect among treatment differences more effectively.</p>
<p>For example, consider the following matrix: the rows are the blocks, the letters the different treatments. In each block, each treatment is represented, but it is in a different location in the block (randomisation of the g treatments in the n units). The blocks are in a sequence - left to right - this could be different days, different locations or different positions on a hillside, for example representing an elevation or soil moisture gradient.</p>
<p>The Blocks are designed to ‘capture’ that underlying source of variability and allow us to detect among treatment differences more effectively.</p>
<pre><code>##      [,1] [,2] [,3] [,4] [,5]
## [1,] "A"  "B"  "A"  "E"  "D" 
## [2,] "C"  "A"  "D"  "C"  "A" 
## [3,] "D"  "E"  "B"  "D"  "C" 
## [4,] "E"  "C"  "E"  "B"  "E" 
## [5,] "B"  "D"  "C"  "A"  "B"</code></pre>
<p>Here is another picture of a block design that moves from just letters to something more literal.</p>
<div class="inline-figure"><img src="images/BlockDesignGraphic.png" width="320"></div>
<p>The blocks are arranged along a gradient, say along the side of a hill, so represent low and high elevation and associated soil moisture. The blocks capture this background variation. THEN, each treatment level (1-4) is allocated a random position in each block.  In the end, each treatment level is replicated across blocks (n = 6!). From: <a href="https://www.researchgate.net/publication/322369242_Randomized_Block_Design_probiotic_example/figures?lo=1" class="uri">https://www.researchgate.net/publication/322369242_Randomized_Block_Design_probiotic_example/figures?lo=1</a></p>
<p>It is important to note that blocks exist at the time of the randomization of treatments to units. We cannot impose blocking structure on a completely randomized design after the fact; either the randomization was blocked or it was not.</p>
<p>We use an RCB to increase the power and precision of an experiment by decreasing the error variance. This decrease in error variance is achieved by finding groups of units that are homogeneous (blocks) and, in effect, repeating the experiment independently in the different blocks. The RCB is an effective design when there is a single source of extraneous variation in the responses that we can identify ahead of time and use to partition the units into blocks.</p>
<p>In short ALWAYS block your experiment, if you can.</p>
<p>You can have spatial blocks, or temporal blocks where you repeat the experiment at different times, or block by batch.</p>
<p>In general, any source of variation that you think may influence the response and which can be identified prior to the experiment is a candidate for blocking.</p>
</div>
<div id="an-example-of-the-rcbd" class="section level2" number="5.4">
<h2>
<span class="header-section-number">5.4</span> An example of the RCBD<a class="anchor" aria-label="anchor" href="#an-example-of-the-rcbd"><i class="fas fa-link"></i></a>
</h2>
<p>Lets modify our previous example to including blocking. If you wish to replicate the analysis, the data are <code>plantYield_Blocked.csv</code>. In these data, the means are similar to <code>plantYield</code> above, but Herbicide 1 is 10 units higher than the control and Herbicide 2 is 9 units higher. Furthermore, block 1 is supposed to be ~10 units higher than blocks 2,3,4 while block 5 is ~10 units lower.</p>
<pre><code>##    plots block   treat      obs
## 1     11     1 Placebo 31.18707
## 2     12     1 Control 31.99603
## 3     13     1   Herb2 41.29937
## 4     14     1   Herb1 41.12746
## 5     21     2 Control 21.08111
## 6     22     2   Herb1 30.56917
## 7     23     2   Herb2 28.09290
## 8     24     2 Placebo 21.02990
## 9     31     3   Herb2 27.44097
## 10    32     3   Herb1 30.29749</code></pre>
</div>
<div id="analysing-the-crbd" class="section level2" number="5.5">
<h2>
<span class="header-section-number">5.5</span> Analysing the CRBD<a class="anchor" aria-label="anchor" href="#analysing-the-crbd"><i class="fas fa-link"></i></a>
</h2>
<p>I’ll leave it to you now to generate the following plot of the means ± standard errors from the <code>plantYield_Blocked.csv</code> file.</p>
<p>This requires thinking hard about the use of dplyr tools (<code>group_by()</code> and <code>summarise()</code>) and ggplot (adding more than one layer from two different sources of data - the summary data and the raw data). You need to make a <em>sumDat</em> object for the means and se’s. Then you need to plot the raw data, and overlay the mean±se info from the sumDat.</p>
<p>Can you see the variation between block 1 and 5? Block 2-4 are all similar…. Block 1 is 10 units more, and Block 5 is 10 units less.</p>
<div class="inline-figure"><img src="Experimental-Design,-ANOVA-and-ANCOVA_files/figure-html/unnamed-chunk-22-1.png" width="672"></div>
<div id="building-the-model" class="section level3" number="5.5.1">
<h3>
<span class="header-section-number">5.5.1</span> Building the model<a class="anchor" aria-label="anchor" href="#building-the-model"><i class="fas fa-link"></i></a>
</h3>
<p>In order to understand what’s going on with blocking, and it’s importance, lets build two models. This is a good trick and a good process to learn. The first model is a <em>naive</em> model that ignores block - treating this as a CRB. The second model is the <em>correct</em> model, letting block absorb the variation we can see among the blocks 1, 2-4 and 5.</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># models</span></span>
<span><span class="va">naive_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">obs</span> <span class="op">~</span> <span class="va">treat</span>, <span class="va">plantYield_Block</span><span class="op">)</span></span>
<span><span class="co"># note the order of these factors is important</span></span>
<span><span class="co"># put block first.... so we can absorb this variation first</span></span>
<span><span class="co"># the anova() table is a SEQUENTIAL table!</span></span>
<span><span class="va">block_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">obs</span> <span class="op">~</span> <span class="va">block</span> <span class="op">+</span> <span class="va">treat</span>, <span class="va">plantYield_Block</span><span class="op">)</span> </span>
<span></span>
<span><span class="co"># anova tables</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">naive_model</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: obs
##           Df Sum Sq Mean Sq F value  Pr(&gt;F)  
## treat      3 417.82 139.274  2.5085 0.09579 .
## Residuals 16 888.34  55.521                  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">block_model</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: obs
##           Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## block      4 877.08 219.270  233.68 2.871e-11 ***
## treat      3 417.82 139.274  148.43 9.469e-10 ***
## Residuals 12  11.26   0.938                      
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
<p>The first important thing to focus on here is the difference in the Mean Sq Residual Errors - in the <code>naive_model</code>, it is <span class="math inline">\(55.52\)</span>. In the <code>block_model</code>, it is <span class="math inline">\(0.94\)</span>. Wow…. a massive reduction in the residual error…. where has it gone?</p>
<p>The second important thing to notice is that having allocated variation to block in the <code>block_model</code>, and thus reducing the error variation, the <em>treatment</em> effect shifts from being insignificant to significant. At this point you should try and recall how F-tests are generated (what is the equation!) to really understand how blocking has made such a different.</p>
</div>
<div id="are-the-estimates-of-the-parameters-what-we-expect" class="section level3" number="5.5.2">
<h3>
<span class="header-section-number">5.5.2</span> Are the estimates of the parameters what we expect?<a class="anchor" aria-label="anchor" href="#are-the-estimates-of-the-parameters-what-we-expect"><i class="fas fa-link"></i></a>
</h3>
<p>Lets check that the model is estimating differences as we might have expected. We can do this using the summary table.</p>
<p>Let’s remember that, for example, the mean of Herb1 is expected to be 10 units higher than control with a yield of 20, and block 1 is supposed to be ~10 units higher than 2,3,4.</p>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">block_model</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = obs ~ block + treat, data = plantYield_Block)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.3505 -0.7196  0.2147  0.6396  1.0719 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   31.2184     0.6126  50.957 2.14e-15 ***
## block2       -11.2092     0.6850 -16.365 1.43e-09 ***
## block3       -12.1132     0.6850 -17.685 5.84e-10 ***
## block4       -11.3415     0.6850 -16.558 1.25e-09 ***
## block5       -20.8449     0.6850 -30.433 9.94e-13 ***
## treatHerb1    10.3450     0.6126  16.886 9.96e-10 ***
## treatHerb2     9.0721     0.6126  14.808 4.50e-09 ***
## treatPlacebo   1.3192     0.6126   2.153   0.0523 .  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.9687 on 12 degrees of freedom
## Multiple R-squared:  0.9914, Adjusted R-squared:  0.9864 
## F-statistic: 197.1 on 7 and 12 DF,  p-value: 2.009e-11</code></pre>
<p>In this table, the <em>INTERCEPT</em> is specifying the <strong>FIRST BLOCK</strong> and the <strong>CONTROL TREATMENT LEVEL</strong>. We know this because it’s these words that are missing from the rest of the table, and they are each the first alpha-numerially in the list of blocks and treatments. Make sure you understand this. It’s tricky, but once you get it, it becomes obvious…. look for what is missing from the rest of the table!</p>
<ul>
<li>The value of the control, block 1 is approximately 30! Which is 20+10, which is what we expected.</li>
<li>The value of Herb1 is ~10 units higher than this (remember, the value 9.84 is the DIFFERENCE between the control and treatment).</li>
<li>And the value of block 5 is reported as 20 unites lower than block 1 control. This too is correct because, as above, block 1 control is 10 units higher than the control mean (20+10) and block 5 is 10 units lower….</li>
</ul>
<p><em>Make sure you get this logic!</em></p>
<p>The take home message here is that these numbers from the model make complete sense with respect to the actual data. Furthermore, controlling for the among block variation <em>gave us more power to detect a treatment effect</em>, something we would have missed had we not estimated the block source of variation.</p>
</div>
<div id="correct-standard-errors-for-a-figure" class="section level3" number="5.5.3">
<h3>
<span class="header-section-number">5.5.3</span> Correct Standard Errors for a Figure<a class="anchor" aria-label="anchor" href="#correct-standard-errors-for-a-figure"><i class="fas fa-link"></i></a>
</h3>
<p>When we made our initial plot above, we calculated the standard error based on all observations among blocks. However, the variation we really wish to represent is the variation after having controlled for the blocking effects. This means that the standard deviation we should probably use is of the error variance from the correct model: <span class="math inline">\(0.94\)</span>. Can you see where this comes from? The <code>Mean Sq</code> column and <code>Residuals</code> row from the <code><a href="https://rdrr.io/r/stats/anova.html">anova()</a></code> table.</p>
<p>The standard deviation is the <span class="math inline">\(\sqrt{Var}\)</span> and thus, our correct standard errors from the model are <span class="math inline">\(\sqrt{0.94}\)</span></p>
<div id="visreg---a-helpful-package-for-automating-this." class="section level4" number="5.5.3.1">
<h4>
<span class="header-section-number">5.5.3.1</span> <code>visreg</code> - a helpful package for automating this.<a class="anchor" aria-label="anchor" href="#visreg---a-helpful-package-for-automating-this."><i class="fas fa-link"></i></a>
</h4>
<p>There is a very nice plotting function in the package <em>visreg</em> that delivers these proper standard errors in a nice ggplot framework.</p>
<p>It presents points that are the partial residuals (deviation from the mean for each replicate), lines depicting the means, and shaded area as a 95% confidence interval, calculated as <span class="math inline">\(1.96*SE\)</span>, where <em>the SE is estimated from the model error variance</em> (just above). Compare this to your first graph.</p>
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">visreg</span><span class="op">(</span><span class="va">block_model</span>, <span class="st">"treat"</span>, gg<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu">ylab</span><span class="op">(</span><span class="st">"Yield"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">xlab</span><span class="op">(</span><span class="st">"Treatment"</span><span class="op">)</span> </span></code></pre></div>
<div class="inline-figure"><img src="Experimental-Design,-ANOVA-and-ANCOVA_files/figure-html/unnamed-chunk-25-1.png" width="672"></div>
</div>
</div>
<div id="making-inference-in-a-blocked-model-confidence-intervals-and-contrasts" class="section level3" number="5.5.4">
<h3>
<span class="header-section-number">5.5.4</span> Making inference in a blocked model: confidence intervals and contrasts<a class="anchor" aria-label="anchor" href="#making-inference-in-a-blocked-model-confidence-intervals-and-contrasts"><i class="fas fa-link"></i></a>
</h3>
<p>We are now in a very strong position to make inference.</p>
<p>Let’s start with a rule of thumb linked to the 95% confidence interval (CI). If the CIs in the figure above don’t overlap, they are different; if they do, they are not. This indicates that Cont and Placebo are not significantly different (95% confidence intervals overlap). Herb1 and Herb 2 are significantly different from these, but not each other.</p>
<p>This is OK. But it is not robust. Instead, let’s revisit our <em>post-hoc</em> and <em>a priori</em> methods for evaluating differences among treatments. We can apply a tukey test and calculate all pairwise differences. This is not a good idea, but let’s do it, using <em>agricolae</em> and the <code>HSD.test()</code> function. Living large!</p>
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># use agricolae HSD.test()</span></span>
<span></span>
<span><span class="va">tukey_out</span> <span class="op">&lt;-</span> <span class="fu">HSD.test</span><span class="op">(</span><span class="va">block_model</span>, <span class="st">"treat"</span>, group <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">tukey_out</span><span class="op">$</span><span class="va">groups</span></span></code></pre></div>
<pre><code>##              obs groups
## Herb1   30.46167      a
## Herb2   29.18874      a
## Placebo 21.43581      b
## Control 20.11665      b</code></pre>
<p>This confirms our intuition and 95% Confidence Interval insights. But is it correct?</p>
<p>Let’s make a formal test, using the <code>contrast()</code> and <code>fit.contrast()</code> functions for of one of the pairwise tests that looks obvious - between Herb1 and Herb2. Even with block in the model, the second argument for <code>fit.contrast()</code> is the treatment for which the contrast is made.</p>
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># fit.contrast from gmodels package</span></span>
<span><span class="co"># see that even with the block in the model</span></span>
<span><span class="va">contrast</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="op">-</span><span class="fl">1</span>,<span class="fl">1</span>,<span class="fl">0</span><span class="op">)</span></span>
<span><span class="fu">fit.contrast</span><span class="op">(</span><span class="va">block_model</span>, <span class="st">"treat"</span>, <span class="va">contrast</span><span class="op">)</span></span></code></pre></div>
<pre><code>##                       Estimate Std. Error   t value   Pr(&gt;|t|)
## treat c=( 0 -1 1 0 ) -1.272934  0.6126423 -2.077777 0.05985811
## attr(,"class")
## [1] "fit_contrast"</code></pre>
<p>Amazing. The contrast defining a specific test provides a different answer than the post-hoc Tukey test. This is important… the Tukey Test makes lots of tests and they are penalised for so many tests. But, the contrast is the correct and most reliable result. While both <em>fit.contrast</em> and <em>HSD.test</em> both manage the model complexity and variance estimates properly, only the contrast reduces the probability of finding a significant difference by chance or failing to find one.</p>

</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="examples-and-challenge-questions.html"><span class="header-section-number">4</span> Examples and Challenge Questions</a></div>
<div class="next"><a href="designs-for-testing-for-interactions-the-two-way-anova-and-factorial-designs..html"><span class="header-section-number">6</span> Designs for testing for interactions: the two-way ANOVA and factorial designs.</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#design-and-analysis-of-experiments"><span class="header-section-number">5</span> Design and Analysis of Experiments</a></li>
<li>
<a class="nav-link" href="#a-crd-completely-randomised-design-example"><span class="header-section-number">5.1</span> A CRD (Completely Randomised Design) Example</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#the-dplyr-and-ggplot-pipeline-for-inference."><span class="header-section-number">5.1.1</span> The dplyr and ggplot pipeline for inference.</a></li>
<li><a class="nav-link" href="#the-one-way-anova."><span class="header-section-number">5.1.2</span> The One-Way ANOVA.</a></li>
<li><a class="nav-link" href="#making-insight-and-inference"><span class="header-section-number">5.1.3</span> Making insight and inference</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#a-priori-vs.-post-hoc-contrasts"><span class="header-section-number">5.2</span> A priori vs. Post-Hoc Contrasts</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#custom-contrasts-versus-the-tukey-test"><span class="header-section-number">5.2.1</span> Custom contrasts versus the Tukey Test</a></li>
<li><a class="nav-link" href="#the-write-up-using-contrasts."><span class="header-section-number">5.2.2</span> The Write Up using contrasts.</a></li>
<li><a class="nav-link" href="#coming-back-to-randomisation"><span class="header-section-number">5.2.3</span> Coming Back to Randomisation</a></li>
</ul>
</li>
<li><a class="nav-link" href="#the-rcbd---the-randomised-complete-block-design"><span class="header-section-number">5.3</span> THE RCBD - The Randomised Complete Block Design</a></li>
<li><a class="nav-link" href="#an-example-of-the-rcbd"><span class="header-section-number">5.4</span> An example of the RCBD</a></li>
<li>
<a class="nav-link" href="#analysing-the-crbd"><span class="header-section-number">5.5</span> Analysing the CRBD</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#building-the-model"><span class="header-section-number">5.5.1</span> Building the model</a></li>
<li><a class="nav-link" href="#are-the-estimates-of-the-parameters-what-we-expect"><span class="header-section-number">5.5.2</span> Are the estimates of the parameters what we expect?</a></li>
<li><a class="nav-link" href="#correct-standard-errors-for-a-figure"><span class="header-section-number">5.5.3</span> Correct Standard Errors for a Figure</a></li>
<li><a class="nav-link" href="#making-inference-in-a-blocked-model-confidence-intervals-and-contrasts"><span class="header-section-number">5.5.4</span> Making inference in a blocked model: confidence intervals and contrasts</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>An Introduction to Experimental Design ANOVA and ANCOVA</strong>" was written by Andrew P Beckerman (with support from text and slides from Mark Rees and Gareth Phoenix). It was last built on 2022-12-05.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
